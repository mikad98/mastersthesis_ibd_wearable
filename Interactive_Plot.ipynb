{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHgY9noWY2xZDelTxc4+yp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "hsiCxft6brry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkr8DPYWnX7Q",
        "outputId": "55ade629-8c52-4170-bfb3-464e11887c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "from datetime import date\n",
        "from scipy.stats import linregress\n",
        "from google.colab import drive\n",
        "from scipy.optimize import curve_fit\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "from matplotlib import cm, colors as mcolors\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interactive_output, HBox, VBox\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "hB35aOIwhxsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjective = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/Data/raw_subjective_data_2025-11-06.csv')\n",
        "\n",
        "subjective.drop(['hasOtherHealthProblems',\n",
        "                 'hrvMeasurement',\n",
        "                 'stressType',\n",
        "                 'otherSymptoms_x',\n",
        "                 'otherHealthProblems',\n",
        "                 'mentalStressLevel',\n",
        "                 'medication',\n",
        "                 'otherMedication_x',\n",
        "                 'otherSymptoms_y',\n",
        "                 'alcoholPortions',\n",
        "                 'notes',\n",
        "                 'diseaseRelapsesEvaluation',\n",
        "                 'generalCondition',\n",
        "                 'complications',\n",
        "                 'stoolsPerDay',\n",
        "                 'stoolsPerNight',\n",
        "                 'urgencyOfDefecation',\n",
        "                 'bloodInStool',\n",
        "                 'stomachPain',\n",
        "                 'unformedStoolsPerDay',\n",
        "                 'abdominalResistance',\n",
        "                 'terraUserId',\n",
        "                 'additionalIllnesses',\n",
        "                 'otherKnownCatalysts',\n",
        "                 'flaresPerYear',\n",
        "                 'hrvMeasurementMethod',\n",
        "                 'backendSymptoms',\n",
        "                 'hrvMeasurementMethodName',\n",
        "                 'hasAskedToConnectWearable',\n",
        "                 'hasConnectedWearable',\n",
        "                 'knownCatalysts',\n",
        "                 'backendKnownCatalysts',\n",
        "                 'connectedWearableName',\n",
        "                 'hasStoma',\n",
        "                 'otherAdditionalIllnesses'\n",
        "                 ], axis=1, inplace=True)\n",
        "\n",
        "# Helper Functions\n",
        "def year_to_age(year_of_birth):\n",
        "    current_year = date.today().year\n",
        "    try:\n",
        "        year = float(year_of_birth)\n",
        "        if year <= 0 or year > current_year:\n",
        "            return None\n",
        "        return int(current_year - year)\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "# Mappings\n",
        "activity_mapping = {\n",
        "        'zero': 0,\n",
        "        'below30min': 1,\n",
        "        'below1h': 2,\n",
        "        'below2h': 3,\n",
        "        'below4h': 4,\n",
        "        'below8h': 5,\n",
        "        'above8h': 6\n",
        "    }\n",
        "\n",
        "diagnosis_mapping = {\n",
        "        \"colitisUlcerosa\": \"UC\",\n",
        "        \"crohnsDisease\": \"CD\",\n",
        "        \"Crohn's disease\": \"CD\",\n",
        "    }\n",
        "\n",
        "gender_mapping = {\n",
        "        \"female\": \"F\",\n",
        "        \"male\": \"M\"\n",
        "    }\n",
        "\n",
        "alcohol_mapping = {\n",
        "        \"Yes\": 2,\n",
        "        \"A little\": 1,\n",
        "        \"No\": 0,\n",
        "        \"Unsure\": np.nan\n",
        "    }\n",
        "\n",
        "period_mapping = {\n",
        "        \"Yes\": 1,\n",
        "        \"Unsure\": 0,\n",
        "        \"False\": np.nan,\n",
        "        \"No\": 0,\n",
        "    }\n",
        "\n",
        "subjective['date'] = pd.to_datetime(subjective['date'], format='mixed').dt.normalize()\n",
        "subjective['age'] = subjective['yearOfBirth'].apply(year_to_age)\n",
        "\n",
        "subjective['hasConsumedAlcoholInLast24Hours'] = subjective['hasConsumedAlcoholInLast24Hours'].map(alcohol_mapping)\n",
        "subjective['activity_dur'] = subjective['physicalEffort'].map(activity_mapping)\n",
        "subjective['diagnosis'] = subjective['diagnosis'].map(diagnosis_mapping)\n",
        "subjective['isOnPeriod'] = subjective['isOnPeriod'].map(period_mapping)\n",
        "subjective['gender'] = subjective['gender'].map(gender_mapping)\n",
        "\n",
        "subjective.dropna(subset=[\"gender\", \"diagnosis\"], inplace=True)\n",
        "\n",
        "# Renaming\n",
        "subjective = subjective.rename(columns={\n",
        "                 'userId': 'user_id',\n",
        "                 'sleepQualityDegree': 'sleep',\n",
        "                 'stressLevelDegree': 'stress',\n",
        "                 'physicalActivityExertionDegree': 'activity_deg',\n",
        "                 'symptomDegree': 'symptom_deg',\n",
        "                 'hasConsumedAlcoholInLast24Hours': 'alcohol_last_24h',\n",
        "                 'isOnPeriod': 'on_period',\n",
        "                 'rateAsFlare': 'rate_as_flare',\n",
        "                 })\n",
        "\n",
        "# Reordering columns\n",
        "subjective = subjective[[\n",
        "                 'user_id',\n",
        "                 'date',\n",
        "                 'gender',\n",
        "                 'age',\n",
        "                 'diagnosis',\n",
        "                 'symptoms',\n",
        "                 'alcohol_last_24h',\n",
        "                 'on_period',\n",
        "                 'sleep',\n",
        "                 'stress',\n",
        "                 'activity_dur',\n",
        "                 'activity_deg',\n",
        "                 'symptom_deg',\n",
        "                 'rate_as_flare'\n",
        "                 ]]\n",
        "\n",
        "subjective.head()"
      ],
      "metadata": {
        "id": "cLZuwM_WkF2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_full_cosinor(hrv_values, sampling_interval_minutes=5.0):\n",
        "\n",
        "    y = np.asarray(hrv_values, dtype=float)\n",
        "    y = y[~np.isnan(y)]\n",
        "\n",
        "    # Need enough points to fit 3 parameters\n",
        "    if y.size < 4:\n",
        "        return np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "    # time vector in hours\n",
        "    dt = sampling_interval_minutes / 60.0\n",
        "    t = np.arange(y.size, dtype=float) * dt\n",
        "\n",
        "    # Total duration T (hours) = \"night length\" for this recording\n",
        "    T = y.size * dt\n",
        "    omega_fixed = 2.0 * np.pi / T  # fixed angular frequency\n",
        "\n",
        "    # Model with fixed period T (omega fixed)\n",
        "    def cosinor_model_fixed(t, mesor, amplitude, acrophase):\n",
        "        return mesor + amplitude * np.cos(omega_fixed * t + acrophase)\n",
        "\n",
        "    # Initial guesses\n",
        "    mesor0 = y.mean()\n",
        "    amplitude0 = (y.max() - y.min()) / 2.0\n",
        "    acrophase0 = 0.0\n",
        "    p0 = (mesor0, amplitude0, acrophase0)\n",
        "\n",
        "    try:\n",
        "        params, _ = curve_fit(cosinor_model_fixed, t, y, p0=p0, maxfev=5000)\n",
        "        mesor, amplitude, acrophase = params\n",
        "    except Exception:\n",
        "        return np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "    # Enforce amplitude >= 0 by flipping sign if necessary\n",
        "    if amplitude < 0:\n",
        "        amplitude = -amplitude\n",
        "        acrophase = (acrophase + np.pi) % (2.0 * np.pi)\n",
        "\n",
        "    # Peak time (max of the cosine) in hours, constrained to [0, T)\n",
        "    # peak when omega*t + acrophase = 0 mod 2Ï€ -> t = -acrophase/omega\n",
        "    peak_time = (-acrophase / omega_fixed) % T\n",
        "\n",
        "    return mesor, acrophase, amplitude, peak_time\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Load data\n",
        "# -------------------------------------------------------------------\n",
        "raw_summary_wearable_data = pd.read_csv(\n",
        "    '/content/drive/My Drive/coreway_ml/Thesis - Mika/Data/raw_summary_wearable_data_2025-09-26.csv'\n",
        ")\n",
        "raw_flattened_wearable_data = pd.read_csv(\n",
        "    '/content/drive/My Drive/coreway_ml/Thesis - Mika/Data/raw_flattened_wearable_data_2025-09-26.csv'\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Transform stringified HRV list to actual list\n",
        "# -------------------------------------------------------------------\n",
        "raw_flattened_wearable_data['hrv_rmssd'] = raw_flattened_wearable_data['hrv_rmssd'].apply(\n",
        "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Standardize date columns for merging\n",
        "# -------------------------------------------------------------------\n",
        "raw_summary_wearable_data['date'] = pd.to_datetime(\n",
        "    raw_summary_wearable_data['date'].str.slice(0, 19), errors='coerce'\n",
        ")\n",
        "raw_flattened_wearable_data['date'] = pd.to_datetime(\n",
        "    raw_flattened_wearable_data['date'].str.slice(0, 19), errors='coerce'\n",
        ")\n",
        "\n",
        "objective = pd.merge(\n",
        "    raw_summary_wearable_data,\n",
        "    raw_flattened_wearable_data,\n",
        "    on=['userId', 'date'],\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Use end_time's calendar date as sleep date, extract HH:MM from start/end\n",
        "# -------------------------------------------------------------------\n",
        "objective['date'] = pd.to_datetime(objective['end_time'].str.slice(0, 10), errors='coerce')\n",
        "\n",
        "objective[['start_time', 'end_time']] = (\n",
        "    objective[['start_time', 'end_time']]\n",
        "    .astype('string')\n",
        "    .apply(lambda col: col.str.extract(r'T(\\d{2}:\\d{2})', expand=False))\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Drop unneeded columns\n",
        "# -------------------------------------------------------------------\n",
        "objective.drop([\n",
        "    'terra_user_id',\n",
        "    'provider_y',\n",
        "    'sleep_score',\n",
        "    'delta_temperature',\n",
        "    'user_max_hr_bpm',\n",
        "    'on_demand_reading',\n",
        "    'breaths_start_time',\n",
        "    'breaths_end_time',\n",
        "    'max_breaths_per_min',\n",
        "    'min_breaths_per_min',\n",
        "    'duration_in_bed_seconds',\n",
        "    'num_REM_events',\n",
        "    'duration_long_interruption_seconds',\n",
        "    'duration_short_interruption_seconds',\n",
        "    'num_out_of_bed_events',\n",
        "    'num_wakeup_events',\n",
        "    'sleep_latency_seconds',\n",
        "    'wake_up_latency_seconds',\n",
        "    'max_hr_bpm',\n",
        "    'min_hr_bpm',\n",
        "    'bpm_array_length',\n",
        "    'timestamp_intervals_seconds_hrv_rmssd',\n",
        "    'hrv_rmssd_array_length',\n",
        "    'level',\n",
        "    'timestamp_intervals_seconds_level',\n",
        "    'level_array_length',\n",
        "    'percentage_array_length',\n",
        "    'breaths_per_min_array_length',\n",
        "    'timestamp_intervals_seconds_hrv_sdnn',\n",
        "    'timestamp_intervals_seconds_bpm',\n",
        "    'timestamp_intervals_seconds_percentage',\n",
        "    'timestamp_intervals_seconds_breaths_per_min',\n",
        "    'hrv_sdnn_array_length'\n",
        "], axis=1, inplace=True)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Renaming columns\n",
        "# -------------------------------------------------------------------\n",
        "objective = objective.rename(columns={\n",
        "    'userId': 'user_id',\n",
        "    'provider_x': 'provider',\n",
        "    'start_time': 'start',\n",
        "    'end_time': 'end',\n",
        "    'avg_hr_bpm': 'avg_bpm',\n",
        "    'resting_hr_bpm': 'rhr',\n",
        "    'sleep_efficiency': 'sleep_eff',\n",
        "    'breaths_per_min': 'breaths',\n",
        "    'avg_breaths_per_min': 'avg_breaths',\n",
        "    'avg_saturation_percentage': 'avg_SpO2',\n",
        "    'duration_REM_sleep_state_seconds': 'dur_REM',\n",
        "    'duration_asleep_state_seconds': 'dur_asleep',\n",
        "    'duration_deep_sleep_state_seconds': 'dur_deep',\n",
        "    'duration_light_sleep_state_seconds': 'dur_light',\n",
        "    'duration_awake_state_seconds': 'dur_awake',\n",
        "    'percentage': 'SpO2'\n",
        "})\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Infer sleep length (HH:MM) and keep numeric duration in hours\n",
        "# -------------------------------------------------------------------\n",
        "start_dt = pd.to_datetime(objective['start'], format='%H:%M', errors='coerce')\n",
        "end_dt   = pd.to_datetime(objective['end'],   format='%H:%M', errors='coerce')\n",
        "\n",
        "# Handle crossing midnight (fixed boolean -> timedelta)\n",
        "mask = (end_dt < start_dt).astype(int)\n",
        "end_dt_corrected = end_dt + pd.to_timedelta(mask, unit=\"D\")\n",
        "\n",
        "diff = end_dt_corrected - start_dt\n",
        "length_hours = diff.dt.total_seconds() / 3600.0\n",
        "\n",
        "objective['length'] = (\n",
        "    (diff.dt.seconds // 3600).astype(str).str.zfill(2) + \":\" +\n",
        "    ((diff.dt.seconds % 3600) // 60).astype(str).str.zfill(2)\n",
        ")\n",
        "objective['length_hours'] = length_hours\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Remove duplicates & aggregate; keep longest sleep per day\n",
        "# -------------------------------------------------------------------\n",
        "objective = (\n",
        "    objective\n",
        "    .groupby(['user_id', 'date', 'start', 'end'], as_index=False)\n",
        "    .agg(lambda x: x.dropna().iloc[0] if x.notna().any() else np.nan)\n",
        ")\n",
        "\n",
        "idx_longest = objective.groupby(['user_id', 'date'])['length_hours'].idxmax()\n",
        "objective = objective.loc[idx_longest].reset_index(drop=True)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Convert durations from seconds to hours & compute sleep stage percentages\n",
        "# -------------------------------------------------------------------\n",
        "objective[['dur_asleep', 'dur_REM', 'dur_deep', 'dur_light', 'dur_awake']] /= 3600.0\n",
        "\n",
        "objective[['REM_pct', 'deep_pct', 'light_pct']] = (\n",
        "    objective[['dur_REM', 'dur_deep', 'dur_light']]\n",
        "    .div(objective['dur_asleep'], axis=0) * 100.0\n",
        ")\n",
        "\n",
        "objective['sleep_eff'] = objective['sleep_eff'] * 100.0\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Drop rows with implausible sleep metrics\n",
        "# -------------------------------------------------------------------\n",
        "objective = objective[objective['dur_asleep'] >= 2]\n",
        "\n",
        "objective = objective[\n",
        "    objective['REM_pct'].between(0, 40) &\n",
        "    objective['light_pct'].between(0, 90) &\n",
        "    objective['deep_pct'].between(0, 40)\n",
        "]\n",
        "\n",
        "total_pct = objective['REM_pct'] + objective['light_pct'] + objective['deep_pct']\n",
        "objective = objective[total_pct.between(90, 110)]\n",
        "\n",
        "objective['sleep_eff'] = objective['sleep_eff'].where(\n",
        "    objective['sleep_eff'].between(25, 100), np.nan\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Replace non-physiological values with NaNs\n",
        "# -------------------------------------------------------------------\n",
        "objective['avg_hrv_sdnn'] = objective['avg_hrv_sdnn'].where(\n",
        "    objective['avg_hrv_sdnn'].between(5, 300), np.nan\n",
        ")\n",
        "objective['avg_hrv_rmssd'] = objective['avg_hrv_rmssd'].where(\n",
        "    objective['avg_hrv_rmssd'].between(5, 300), np.nan\n",
        ")\n",
        "objective['avg_SpO2'] = objective['avg_SpO2'].where(\n",
        "    objective['avg_SpO2'].between(85, 100), np.nan\n",
        ")\n",
        "objective['avg_bpm'] = objective['avg_bpm'].where(\n",
        "    objective['avg_bpm'].between(30, 150), np.nan\n",
        ")\n",
        "objective['rhr'] = objective['rhr'].where(\n",
        "    objective['rhr'].between(30, 150), np.nan\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Derive HRV features + cosinor features from hrv_rmssd (single pass)\n",
        "# -------------------------------------------------------------------\n",
        "std_list = []\n",
        "cv_list = []\n",
        "min_list = []\n",
        "max_list = []\n",
        "slope_list = []\n",
        "mesor_list = []\n",
        "acrophase_list = []\n",
        "amplitude_list = []\n",
        "peak_time_list = []\n",
        "\n",
        "for x in objective['hrv_rmssd']:\n",
        "    if isinstance(x, (list, np.ndarray, pd.Series)) and len(x) > 0:\n",
        "        arr = np.asarray(x, dtype='float64')\n",
        "\n",
        "        # Basic HRV stats\n",
        "        std_val = arr.std()\n",
        "        mean_val = arr.mean()\n",
        "        min_val = arr.min()\n",
        "        max_val = arr.max()\n",
        "\n",
        "        if arr.size > 1:\n",
        "            slope = linregress(np.arange(arr.size), arr).slope\n",
        "        else:\n",
        "            slope = np.nan\n",
        "\n",
        "        # Cosinor with period exactly matching this recording's length\n",
        "        mesor, acrophase, amplitude, peak_time = fit_full_cosinor(\n",
        "            arr, sampling_interval_minutes=5.0\n",
        "        )\n",
        "\n",
        "        std_list.append(std_val)\n",
        "        cv_list.append(std_val / mean_val if mean_val != 0 else np.nan)\n",
        "        min_list.append(min_val)\n",
        "        max_list.append(max_val)\n",
        "        slope_list.append(slope)\n",
        "        mesor_list.append(mesor)\n",
        "        acrophase_list.append(acrophase)\n",
        "        amplitude_list.append(amplitude)\n",
        "        peak_time_list.append(peak_time)\n",
        "    else:\n",
        "        std_list.append(np.nan)\n",
        "        cv_list.append(np.nan)\n",
        "        min_list.append(np.nan)\n",
        "        max_list.append(np.nan)\n",
        "        slope_list.append(np.nan)\n",
        "        mesor_list.append(np.nan)\n",
        "        acrophase_list.append(np.nan)\n",
        "        amplitude_list.append(np.nan)\n",
        "        peak_time_list.append(np.nan)\n",
        "\n",
        "objective['std_rmssd'] = std_list\n",
        "objective['cv_rmssd'] = cv_list\n",
        "objective['min_rmssd'] = min_list\n",
        "objective['max_rmssd'] = max_list\n",
        "objective['range_rmssd'] = objective['max_rmssd'] - objective['min_rmssd']\n",
        "objective['slope_rmssd'] = slope_list\n",
        "\n",
        "objective['mesor_rmssd'] = mesor_list\n",
        "objective['acrophase_rmssd'] = acrophase_list\n",
        "objective['amplitude_rmssd'] = amplitude_list\n",
        "objective['peak_time_rmssd'] = peak_time_list\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Reordering columns (now including cosinor features)\n",
        "# -------------------------------------------------------------------\n",
        "objective = objective[[\n",
        "    'user_id',\n",
        "    'date',\n",
        "    'provider',\n",
        "    'start',\n",
        "    'end',\n",
        "    'length',\n",
        "    'length_hours',\n",
        "    'sleep_eff',\n",
        "    'dur_asleep',\n",
        "    'dur_REM',\n",
        "    'REM_pct',\n",
        "    'dur_deep',\n",
        "    'deep_pct',\n",
        "    'dur_light',\n",
        "    'light_pct',\n",
        "    'dur_awake',\n",
        "    'hrv_rmssd',\n",
        "    'avg_hrv_rmssd',\n",
        "    'std_rmssd',\n",
        "    'cv_rmssd',\n",
        "    'min_rmssd',\n",
        "    'max_rmssd',\n",
        "    'range_rmssd',\n",
        "    'slope_rmssd',\n",
        "    'mesor_rmssd',\n",
        "    'acrophase_rmssd',\n",
        "    'amplitude_rmssd',\n",
        "    'peak_time_rmssd',\n",
        "    'avg_hrv_sdnn',\n",
        "    'avg_bpm',\n",
        "    'rhr',\n",
        "    'avg_SpO2',\n",
        "    'avg_breaths'\n",
        "]]\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# Sorting\n",
        "# -------------------------------------------------------------------\n",
        "objective = objective.sort_values(\n",
        "    by=['user_id', 'date', 'start', 'end']\n",
        ").reset_index(drop=True)\n",
        "\n",
        "objective.head()"
      ],
      "metadata": {
        "id": "KqkMat3lrZdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged = pd.merge(subjective, objective, on=['user_id', 'date'], how='outer', indicator=True)\n",
        "\n",
        "merged.head()"
      ],
      "metadata": {
        "id": "saRgSqZ1vEMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interactive Plot"
      ],
      "metadata": {
        "id": "-Ue4jBIwh9fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure date is datetime\n",
        "merged['date'] = pd.to_datetime(merged['date'])\n",
        "\n",
        "# Map friendly names to _merge values\n",
        "DATA_TYPE_MAP = {\n",
        "    'multimodal': 'both',\n",
        "    'objective': 'right_only',\n",
        "    'subjective': 'left_only'\n",
        "}\n",
        "\n",
        "data_type_filter = widgets.ToggleButtons(\n",
        "    options=[\n",
        "        ('Multimodal', 'multimodal'),\n",
        "        ('Objective', 'objective'),\n",
        "        ('Subjective', 'subjective')\n",
        "    ],\n",
        "    value='multimodal',\n",
        "    description='Data type:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "min_days_filter = widgets.BoundedIntText(\n",
        "    value=100,\n",
        "    min=1,\n",
        "    max=10000,\n",
        "    step=10,\n",
        "    description='Min days:',\n",
        "    layout=widgets.Layout(width='160px')\n",
        ")\n",
        "\n",
        "def _get_filtered_users(data_type_value, min_days):\n",
        "\n",
        "    merge_value = DATA_TYPE_MAP[data_type_value]\n",
        "    mask = merged['_merge'] == merge_value\n",
        "    counts = merged[mask].groupby('user_id').size()\n",
        "    eligible = counts[counts >= min_days].index.tolist()\n",
        "    return sorted(eligible)\n",
        "\n",
        "# ----------------------------\n",
        "# Widgets\n",
        "# ----------------------------\n",
        "\n",
        "initial_users = _get_filtered_users(data_type_filter.value, min_days_filter.value)\n",
        "user_selector = widgets.ToggleButtons(\n",
        "    options=initial_users,\n",
        "    description='user_id:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "def _update_user_options(change=None):\n",
        "\n",
        "    eligible = _get_filtered_users(data_type_filter.value, min_days_filter.value)\n",
        "    if len(eligible) == 0:\n",
        "        user_selector.options = []\n",
        "        return\n",
        "\n",
        "    # Update options\n",
        "    prev_value = user_selector.value if user_selector.value in eligible else None\n",
        "    user_selector.options = eligible\n",
        "\n",
        "    # If previous selection invalid or None, default to first eligible user\n",
        "    if prev_value is None:\n",
        "        user_selector.value = eligible[0]\n",
        "\n",
        "# Attach observers\n",
        "data_type_filter.observe(_update_user_options, names='value')\n",
        "min_days_filter.observe(_update_user_options, names='value')\n",
        "\n",
        "feature_options = [\n",
        "    'sleep', 'stress', 'activity_dur', 'activity_deg',\n",
        "    'sleep_eff', 'dur_asleep', 'dur_REM', 'REM_pct', 'dur_deep',\n",
        "    'deep_pct', 'dur_light', 'light_pct', 'dur_awake', 'avg_hrv_rmssd',\n",
        "    'std_rmssd', 'cv_rmssd', 'min_rmssd', 'max_rmssd', 'range_rmssd',\n",
        "    'slope_rmssd', 'mesor_rmssd', 'acrophase_rmssd', 'amplitude_rmssd',\n",
        "    'peak_time_rmssd', 'avg_hrv_sdnn', 'avg_bpm', 'rhr', 'avg_SpO2',\n",
        "    'avg_breaths'\n",
        "]\n",
        "\n",
        "feature_selector = widgets.SelectMultiple(\n",
        "    options=feature_options,\n",
        "    value=('stress', 'REM_pct', 'deep_pct', 'light_pct', 'rhr'),\n",
        "    description='Features',\n",
        "    layout=widgets.Layout(width='250px', height='220px')\n",
        ")\n",
        "\n",
        "smooth_checkbox = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Apply smoothing',\n",
        "    indent=False\n",
        ")\n",
        "\n",
        "smooth_window = widgets.BoundedIntText(\n",
        "    value=30,\n",
        "    min=1,\n",
        "    max=60,\n",
        "    step=1,\n",
        "    description='Window:',\n",
        "    layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "layout_selector = widgets.ToggleButtons(\n",
        "    options=[('Overlay', 'overlay'), ('Stacked', 'stacked')],\n",
        "    value='stacked',\n",
        "    description='Layout:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Plot style selector\n",
        "plot_style_selector = widgets.ToggleButtons(\n",
        "    options=[\n",
        "        ('Line + Scatter', 'line_scatter'),\n",
        "        ('Line only', 'line'),\n",
        "        ('Scatter only', 'scatter')\n",
        "    ],\n",
        "    value='line_scatter',\n",
        "    description='Style:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Variability band controls\n",
        "variability_checkbox = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show variability band',\n",
        "    indent=False\n",
        ")\n",
        "\n",
        "variability_std_text = widgets.FloatText(\n",
        "    value=1.0,\n",
        "    description='Std band:',\n",
        "    layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Anomaly detection widgets\n",
        "# -------------------------\n",
        "anomaly_method_selector = widgets.ToggleButtons(\n",
        "    options=[\n",
        "        ('None', 'none'),\n",
        "        ('EllipticEnvelope', 'elliptic'),\n",
        "        ('StdDev-based', 'std'),\n",
        "        ('CuSum (two-sided)', 'cusum_two')\n",
        "    ],\n",
        "    value='none',\n",
        "    description='Anomaly:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Shared window settings (always visible)\n",
        "obs_window_widget = widgets.BoundedIntText(\n",
        "    value=60,\n",
        "    min=5,\n",
        "    max=365,\n",
        "    step=1,\n",
        "    description='Obs win:',\n",
        "    layout=widgets.Layout(width='160px')\n",
        ")\n",
        "\n",
        "det_window_widget = widgets.BoundedIntText(\n",
        "    value=7,\n",
        "    min=1,\n",
        "    max=60,\n",
        "    step=1,\n",
        "    description='Det win:',\n",
        "    layout=widgets.Layout(width='160px')\n",
        ")\n",
        "\n",
        "min_obs_widget = widgets.BoundedIntText(\n",
        "    value=15,\n",
        "    min=1,\n",
        "    max=200,\n",
        "    step=1,\n",
        "    description='Min obs:',\n",
        "    layout=widgets.Layout(width='160px')\n",
        ")\n",
        "\n",
        "# EllipticEnvelope params: contamination\n",
        "contamination_text = widgets.FloatText(\n",
        "    value=0.1,\n",
        "    description='Contam:',\n",
        "    layout=widgets.Layout(width='200px')\n",
        ")\n",
        "\n",
        "# StdDev-based params: std_factor\n",
        "std_factor_text = widgets.FloatText(\n",
        "    value=2.0,\n",
        "    description='Std factor:',\n",
        "    layout=widgets.Layout(width='200px')\n",
        ")\n",
        "\n",
        "# CuSum two-sided params\n",
        "alpha_widget = widgets.FloatText(\n",
        "    value=0.01,\n",
        "    description='alpha:',\n",
        "    layout=widgets.Layout(width='160px')\n",
        ")\n",
        "\n",
        "short_term_widget = widgets.ToggleButtons(\n",
        "    options=[('Short', True), ('Long', False)],\n",
        "    value=True,\n",
        "    description='Mode:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "alarm_fraction_widget = widgets.FloatText(\n",
        "    value=0.3,\n",
        "    description='Alarm frac:',\n",
        "    layout=widgets.Layout(width='200px')\n",
        ")\n",
        "\n",
        "detection_logic_widget = widgets.ToggleButtons(\n",
        "    options=[('Fraction', 'fraction'), ('Consecutive', 'consecutive')],\n",
        "    value='fraction',\n",
        "    description='Logic:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Group anomaly-specific widgets into boxes for conditional visibility\n",
        "elliptic_params_box = VBox([widgets.HTML(\"<b>EllipticEnvelope params</b>\"), contamination_text])\n",
        "std_params_box = VBox([widgets.HTML(\"<b>StdDev params</b>\"), std_factor_text])\n",
        "cusum_params_box = VBox([\n",
        "    widgets.HTML(\"<b>CuSum params</b>\"),\n",
        "    alpha_widget,\n",
        "    short_term_widget,\n",
        "    alarm_fraction_widget,\n",
        "    detection_logic_widget\n",
        "])\n",
        "\n",
        "def _set_visible(box, visible: bool):\n",
        "    box.layout.display = '' if visible else 'none'\n",
        "\n",
        "def update_param_visibility(change=None):\n",
        "    method = anomaly_method_selector.value\n",
        "    _set_visible(elliptic_params_box, method == 'elliptic')\n",
        "    _set_visible(std_params_box, method == 'std')\n",
        "    _set_visible(cusum_params_box, method == 'cusum_two')\n",
        "\n",
        "# Attach observer and set initial visibility\n",
        "anomaly_method_selector.observe(update_param_visibility, names='value')\n",
        "update_param_visibility()\n",
        "\n",
        "SYMPTOM_ORDER = [\n",
        "    'flatulence', 'vomiting', 'fever', 'constipation', 'lackOfAppetite',\n",
        "    'bloodInStool', 'nausea', 'jointPain', 'diarrhea', 'stomachPain',\n",
        "    'tiredness'\n",
        "]\n",
        "\n",
        "norm_symptom = mcolors.Normalize(vmin=0, vmax=5)\n",
        "cmap_symptom = cm.get_cmap('RdYlGn_r').copy()\n",
        "cmap_symptom.set_bad(color=(0, 0, 0, 0))\n",
        "\n",
        "norm_symptom_presence = mcolors.Normalize(vmin=0, vmax=1)\n",
        "cmap_symptom_presence = LinearSegmentedColormap.from_list(\n",
        "    \"symptom_presence_grey\",\n",
        "    [\"#eeeeee\", \"#7f7f7f\"],\n",
        "    N=256\n",
        ")\n",
        "cmap_symptom_presence.set_bad(color=(0, 0, 0, 0))\n",
        "\n",
        "def parse_symptoms(val):\n",
        "    if pd.isna(val):\n",
        "        return None\n",
        "\n",
        "    if isinstance(val, (list, tuple, set)):\n",
        "        return [str(x).strip() for x in val if str(x).strip()]\n",
        "\n",
        "    s = str(val).strip()\n",
        "    if s.endswith(\"|\"):\n",
        "        s = s[:-1]\n",
        "\n",
        "    try:\n",
        "        parsed = ast.literal_eval(s)\n",
        "        if isinstance(parsed, (list, tuple, set)):\n",
        "            return [str(x).strip() for x in parsed if str(x).strip()]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    out = []\n",
        "    for tok in s.split(\",\"):\n",
        "        c = tok.strip(\" []'\\\"\")\n",
        "        if c:\n",
        "            out.append(c)\n",
        "    return out\n",
        "\n",
        "def anomaly_detection_rolling(df, value_col, contamination=0.1,\n",
        "                              obs_window_days=30, det_window_days=7, min_obs=10):\n",
        "    df = df.copy()\n",
        "    df['anomaly'] = np.nan\n",
        "\n",
        "    for start in range(len(df) - obs_window_days - det_window_days + 1):\n",
        "        obs_idx = df.index[start: start + obs_window_days]\n",
        "        obs_mask = df.loc[obs_idx, value_col].notna()\n",
        "\n",
        "        if obs_mask.sum() >= min_obs:\n",
        "            model = EllipticEnvelope(\n",
        "                contamination=contamination,\n",
        "                random_state=42,\n",
        "                support_fraction=1\n",
        "            )\n",
        "            model.fit(df.loc[obs_idx[obs_mask], [value_col]])\n",
        "\n",
        "            det_idx = df.index[start + obs_window_days:\n",
        "                               start + obs_window_days + det_window_days]\n",
        "            det_mask = df.loc[det_idx, value_col].notna()\n",
        "            if det_mask.sum() > 0:\n",
        "                df.loc[det_idx[det_mask], 'anomaly'] = model.predict(\n",
        "                    df.loc[det_idx[det_mask], [value_col]]\n",
        "                )\n",
        "\n",
        "    return df\n",
        "\n",
        "def anomaly_detection_std(df, value_col, obs_window_days=30,\n",
        "                          det_window_days=7, min_obs=10, std_factor=2.0):\n",
        "    df = df.copy()\n",
        "    df['anomaly'] = np.nan\n",
        "    values = df[value_col].values\n",
        "    n = len(values)\n",
        "\n",
        "    for start in range(n - obs_window_days - det_window_days + 1):\n",
        "        obs_slice = slice(start, start + obs_window_days)\n",
        "        det_slice = slice(start + obs_window_days,\n",
        "                          start + obs_window_days + det_window_days)\n",
        "\n",
        "        obs_window = values[obs_slice]\n",
        "        obs_window = obs_window[~np.isnan(obs_window)]\n",
        "\n",
        "        if len(obs_window) < min_obs:\n",
        "            continue\n",
        "\n",
        "        mean = np.nanmean(obs_window)\n",
        "        std = np.nanstd(obs_window)\n",
        "\n",
        "        if not np.isfinite(std) or std == 0:\n",
        "            continue\n",
        "\n",
        "        det_values = values[det_slice]\n",
        "        idx_det = df.index[det_slice]\n",
        "\n",
        "        diff = np.abs(det_values - mean)\n",
        "        is_anom = diff > std_factor * std\n",
        "\n",
        "        valid_mask = ~np.isnan(det_values)\n",
        "        df.loc[idx_det[valid_mask], 'anomaly'] = 1\n",
        "        df.loc[idx_det[valid_mask & is_anom], 'anomaly'] = -1\n",
        "\n",
        "    return df\n",
        "\n",
        "def anomaly_detection_cusum_two_sided(df, value_col, obs_window_days=60, det_window_days=7,\n",
        "                                      short_term=True, alpha=0.01, min_obs=15,\n",
        "                                      alarm_fraction=0.3, detection_logic=\"fraction\"):\n",
        "    df = df.copy()\n",
        "    df['cusum_pos'] = np.nan\n",
        "    df['cusum_neg'] = np.nan\n",
        "    df['anomaly'] = np.nan\n",
        "    df = df.sort_index()\n",
        "\n",
        "    values = df[value_col].values\n",
        "    n = len(values)\n",
        "\n",
        "    for start in range(n - obs_window_days - det_window_days + 1):\n",
        "        obs_slice = slice(start, start + obs_window_days)\n",
        "        det_slice = slice(start + obs_window_days,\n",
        "                          start + obs_window_days + det_window_days)\n",
        "\n",
        "        obs_window = values[obs_slice]\n",
        "        obs_window = obs_window[~np.isnan(obs_window)]\n",
        "\n",
        "        if len(obs_window) < min_obs:\n",
        "            continue\n",
        "\n",
        "        q = np.nanquantile(obs_window, 0.9 if short_term else 0.99)\n",
        "        k = 0.5 * q\n",
        "\n",
        "        null_pos = np.zeros(len(obs_window))\n",
        "        null_neg = np.zeros(len(obs_window))\n",
        "\n",
        "        for i in range(1, len(obs_window)):\n",
        "            x = obs_window[i]\n",
        "            null_pos[i] = max(0, null_pos[i - 1] + (x - k))\n",
        "            null_neg[i] = max(0, null_neg[i - 1] + (-x - k))\n",
        "\n",
        "        threshold_pos = np.nanquantile(null_pos, 1 - alpha)\n",
        "        threshold_neg = np.nanquantile(null_neg, 1 - alpha)\n",
        "\n",
        "        det_values = values[det_slice]\n",
        "        S_pos = np.zeros(len(det_values))\n",
        "        S_neg = np.zeros(len(det_values))\n",
        "\n",
        "        for i in range(1, len(det_values)):\n",
        "            x = det_values[i]\n",
        "            if np.isnan(x):\n",
        "                S_pos[i] = S_pos[i - 1]\n",
        "                S_neg[i] = S_neg[i - 1]\n",
        "                continue\n",
        "\n",
        "            S_pos[i] = max(0, S_pos[i - 1] + (x - k))\n",
        "            S_neg[i] = max(0, S_neg[i - 1] + (-x - k))\n",
        "\n",
        "        df.loc[df.index[det_slice], 'cusum_pos'] = S_pos\n",
        "        df.loc[df.index[det_slice], 'cusum_neg'] = S_neg\n",
        "\n",
        "        alarm_pos = np.where(S_pos > threshold_pos)[0]\n",
        "        alarm_neg = np.where(S_neg > threshold_neg)[0]\n",
        "\n",
        "        total_alarm = len(alarm_pos) + len(alarm_neg)\n",
        "        alarm_ratio = total_alarm / det_window_days\n",
        "\n",
        "        if detection_logic == \"consecutive\":\n",
        "            pos_run = len(alarm_pos) > 1\n",
        "            neg_run = len(alarm_neg) > 1\n",
        "\n",
        "            if pos_run or neg_run:\n",
        "                df.loc[df.index[det_slice], 'anomaly'] = -1\n",
        "            else:\n",
        "                df.loc[df.index[det_slice], 'anomaly'] = 1\n",
        "\n",
        "        elif detection_logic == \"fraction\":\n",
        "            if alarm_ratio >= alarm_fraction:\n",
        "                df.loc[df.index[det_slice], 'anomaly'] = -1\n",
        "            else:\n",
        "                df.loc[df.index[det_slice], 'anomaly'] = 1\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Main plotting function\n",
        "# ----------------------------\n",
        "def plot_user(user_id, features, smooth, window, layout_mode, plot_style,\n",
        "              anomaly_method,\n",
        "              contamination, std_factor,\n",
        "              obs_window_days, det_window_days, min_obs,\n",
        "              alpha, short_term, alarm_fraction, detection_logic,\n",
        "              variability_band, variability_std):\n",
        "\n",
        "    features = list(features)\n",
        "    df = merged[merged[\"user_id\"] == user_id].sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "    if df.empty:\n",
        "        fig, ax = plt.subplots(figsize=(16, 8))\n",
        "        ax.text(0.5, 0.5, f\"No data for user {user_id}\",\n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.axis(\"off\")\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "    n_dates = len(df)\n",
        "    w = int(window)\n",
        "\n",
        "    uid_str = str(user_id)\n",
        "    uid_short = uid_str[:7] + \"...\" if len(uid_str) > 7 else uid_str\n",
        "\n",
        "    age = df['age'].dropna().iloc[0] if 'age' in df.columns and df['age'].notna().any() else \"NA\"\n",
        "    gender = df['gender'].dropna().iloc[0] if 'gender' in df.columns and df['gender'].notna().any() else \"NA\"\n",
        "    diagnosis = df['diagnosis'].dropna().iloc[0] if 'diagnosis' in df.columns and df['diagnosis'].notna().any() else \"NA\"\n",
        "\n",
        "    user_title = f\"User: {uid_short}, Age: {age}, Gender: {gender}, Diagnosis: {diagnosis}\"\n",
        "\n",
        "    # Parse symptoms\n",
        "    parsed_symptoms_per_row = []\n",
        "    present_symptoms = set()\n",
        "\n",
        "    for val in df[\"symptoms\"]:\n",
        "        items = parse_symptoms(val)\n",
        "        parsed_symptoms_per_row.append(items)\n",
        "        if items is not None:\n",
        "            for s in items:\n",
        "                if s in SYMPTOM_ORDER:\n",
        "                    present_symptoms.add(s)\n",
        "\n",
        "    all_symptoms = [s for s in SYMPTOM_ORDER if s in present_symptoms]\n",
        "    n_sym = len(all_symptoms)\n",
        "    sym_idx = {s: i for i, s in enumerate(all_symptoms)}\n",
        "\n",
        "    dates = df[\"date\"]\n",
        "    dates_num = mdates.date2num(dates)\n",
        "\n",
        "    # symptom_deg\n",
        "    if \"symptom_deg\" in df.columns:\n",
        "        deg_series = pd.to_numeric(df[\"symptom_deg\"], errors=\"coerce\")\n",
        "    else:\n",
        "        deg_series = pd.Series([np.nan] * n_dates, index=df.index)\n",
        "\n",
        "    # flare\n",
        "    if \"rate_as_flare\" in df.columns:\n",
        "        flare_series = df[\"rate_as_flare\"]\n",
        "    else:\n",
        "        flare_series = pd.Series([np.nan] * n_dates, index=df.index)\n",
        "\n",
        "    flare_map = {\"No\": 1.0, \"Unsure\": 3.0, \"Yes\": 4.0}\n",
        "    flare_numeric = np.full(n_dates, np.nan)\n",
        "    for i, v in enumerate(flare_series):\n",
        "        if not pd.isna(v):\n",
        "            flare_numeric[i] = flare_map.get(v, np.nan)\n",
        "\n",
        "    # smoothing for symptom_deg and flare\n",
        "    if smooth and w > 1:\n",
        "        deg_series = deg_series.rolling(window=w, min_periods=1).mean()\n",
        "\n",
        "        flare_series_num = pd.Series(flare_numeric, index=df.index)\n",
        "        flare_series_num = flare_series_num.rolling(window=w, min_periods=1).mean()\n",
        "        flare_numeric = flare_series_num.to_numpy()\n",
        "\n",
        "    # ------------\n",
        "    # feature data\n",
        "    # ------------\n",
        "    data = None\n",
        "    data_std = None\n",
        "\n",
        "    if len(features) > 0:\n",
        "        data = df[[\"date\"] + features].copy()\n",
        "        for f in features:\n",
        "            data[f] = pd.to_numeric(data[f], errors=\"coerce\")\n",
        "\n",
        "        if smooth and w > 1:\n",
        "            rolling_obj = data[features].rolling(window=w, min_periods=1)\n",
        "            data_std = rolling_obj.std()\n",
        "            data[features] = rolling_obj.mean()\n",
        "        else:\n",
        "            data_std = None\n",
        "\n",
        "    # ----------------------------\n",
        "    # Anomaly computation per feature\n",
        "    # ----------------------------\n",
        "    anomalies = {}\n",
        "    if anomaly_method != \"none\" and data is not None and len(features) > 0:\n",
        "        for feat in features:\n",
        "            df_feat = data[[\"date\", feat]].copy()\n",
        "            df_feat = df_feat.set_index(\"date\")\n",
        "            df_feat = df_feat.rename(columns={feat: \"value\"})\n",
        "\n",
        "            if anomaly_method == \"elliptic\":\n",
        "                res = anomaly_detection_rolling(\n",
        "                    df_feat, value_col=\"value\",\n",
        "                    contamination=contamination,\n",
        "                    obs_window_days=obs_window_days,\n",
        "                    det_window_days=det_window_days,\n",
        "                    min_obs=min_obs\n",
        "                )\n",
        "            elif anomaly_method == \"std\":\n",
        "                res = anomaly_detection_std(\n",
        "                    df_feat, value_col=\"value\",\n",
        "                    obs_window_days=obs_window_days,\n",
        "                    det_window_days=det_window_days,\n",
        "                    min_obs=min_obs,\n",
        "                    std_factor=std_factor\n",
        "                )\n",
        "            elif anomaly_method == \"cusum_two\":\n",
        "                res = anomaly_detection_cusum_two_sided(\n",
        "                    df_feat, value_col=\"value\",\n",
        "                    obs_window_days=obs_window_days,\n",
        "                    det_window_days=det_window_days,\n",
        "                    short_term=short_term,\n",
        "                    alpha=alpha,\n",
        "                    min_obs=min_obs,\n",
        "                    alarm_fraction=alarm_fraction,\n",
        "                    detection_logic=detection_logic\n",
        "                )\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            mask = res[\"anomaly\"] == -1\n",
        "            if mask.any():\n",
        "                anomalies[feat] = (res.index[mask], res.loc[mask, \"value\"])\n",
        "\n",
        "    deg_height = 0.3\n",
        "    flare_height = 0.3\n",
        "    heat_height = 0.3 * n_sym if n_sym > 0 else 1.5\n",
        "\n",
        "    if layout_mode == \"overlay\" or len(features) == 0:\n",
        "\n",
        "        series_height = 7.0\n",
        "        total_height = heat_height + deg_height + series_height + flare_height\n",
        "\n",
        "        fig, (ax_heat, ax_deg, ax_feat, ax_flare) = plt.subplots(\n",
        "            4, 1,\n",
        "            sharex=True,\n",
        "            figsize=(16, total_height),\n",
        "            gridspec_kw={\n",
        "                \"height_ratios\": [heat_height, deg_height, series_height, flare_height]\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Symptom presence\n",
        "        if n_sym > 0:\n",
        "            heat_presence = np.full((n_sym, n_dates), np.nan)\n",
        "\n",
        "            for col, items in enumerate(parsed_symptoms_per_row):\n",
        "                if items is None:\n",
        "                    continue\n",
        "                heat_presence[:, col] = 0.0\n",
        "                for s in items:\n",
        "                    if s in sym_idx:\n",
        "                        heat_presence[sym_idx[s], col] = 1.0\n",
        "\n",
        "            if smooth and w > 1:\n",
        "                presence_df = pd.DataFrame(\n",
        "                    heat_presence.T,\n",
        "                    index=df.index,\n",
        "                    columns=all_symptoms\n",
        "                )\n",
        "                presence_df = presence_df.rolling(window=w, min_periods=1).mean()\n",
        "                heat_presence = presence_df.to_numpy().T\n",
        "\n",
        "            ax_heat.imshow(\n",
        "                heat_presence,\n",
        "                aspect=\"auto\",\n",
        "                interpolation=\"none\",\n",
        "                origin=\"lower\",\n",
        "                extent=[dates_num.min() - .5, dates_num.max() + .5, -0.5, n_sym - .5],\n",
        "                cmap=cmap_symptom_presence,\n",
        "                norm=norm_symptom_presence\n",
        "            )\n",
        "            ax_heat.set_yticks(range(n_sym))\n",
        "            ax_heat.set_yticklabels(all_symptoms, fontsize=11)\n",
        "            ax_heat.set_title(\"Symptoms (True / False)\")\n",
        "            ax_heat.tick_params(axis='x', labelbottom=False)\n",
        "\n",
        "        else:\n",
        "            ax_heat.text(0.5, 0.5, \"No selected symptoms\",\n",
        "                         ha='center', va='center', transform=ax_heat.transAxes)\n",
        "            ax_heat.set_yticks([])\n",
        "\n",
        "        # symptom_deg heatmap\n",
        "        heat_deg = np.full((1, n_dates), np.nan)\n",
        "        heat_deg[0, :] = deg_series.values\n",
        "\n",
        "        ax_deg.imshow(\n",
        "            heat_deg,\n",
        "            aspect=\"auto\",\n",
        "            interpolation=\"none\",\n",
        "            origin=\"lower\",\n",
        "            extent=[dates_num.min() - .5, dates_num.max() + .5, -0.5, 0.5],\n",
        "            cmap=cmap_symptom,\n",
        "            norm=norm_symptom\n",
        "        )\n",
        "        ax_deg.set_yticks([0])\n",
        "        ax_deg.set_yticklabels([\"symptom_deg\"], fontsize=11)\n",
        "        ax_deg.set_title(\"Symptom Degree (0-5)\")\n",
        "        ax_deg.tick_params(axis='x', labelbottom=False)\n",
        "\n",
        "        # FEATURE OVERLAY (multi-color)\n",
        "        if data is None or len(features) == 0:\n",
        "            ax_feat.text(0.5, 0.5, \"No feature selected\",\n",
        "                         ha='center', va='center', transform=ax_feat.transAxes)\n",
        "        else:\n",
        "            color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
        "            axes_list = [ax_feat]\n",
        "            anomaly_plotted_label = False\n",
        "            band_label_plotted = False\n",
        "\n",
        "            for i, feat in enumerate(features):\n",
        "                if i == 0:\n",
        "                    ax_i = ax_feat\n",
        "                else:\n",
        "                    ax_i = ax_feat.twinx()\n",
        "                    axes_list.append(ax_i)\n",
        "                    ax_i.spines[\"right\"].set_position((\"outward\", 40 * (i - 1)))\n",
        "\n",
        "                color = color_cycle[i % len(color_cycle)]\n",
        "                x = data[\"date\"]\n",
        "                y = data[feat]\n",
        "\n",
        "                # Variability band when smoothing + checkbox enabled\n",
        "                if (\n",
        "                    smooth and w > 1 and\n",
        "                    variability_band and\n",
        "                    data_std is not None and\n",
        "                    feat in data_std.columns\n",
        "                ):\n",
        "                    y_std = data_std[feat]\n",
        "                    label_band = None\n",
        "                    if not band_label_plotted:\n",
        "                        label_band = f\"Â±{variability_std} std\"\n",
        "                        band_label_plotted = True\n",
        "                    ax_i.fill_between(\n",
        "                        x,\n",
        "                        y - variability_std * y_std,\n",
        "                        y + variability_std * y_std,\n",
        "                        alpha=0.15,\n",
        "                        color=color,\n",
        "                        label=label_band\n",
        "                    )\n",
        "\n",
        "                # chosen plot style\n",
        "                if plot_style in (\"line\", \"line_scatter\"):\n",
        "                    ax_i.plot(x, y, color=color, label=feat)\n",
        "                if plot_style in (\"scatter\", \"line_scatter\"):\n",
        "                    ax_i.scatter(x, y, color=color, s=20)\n",
        "\n",
        "                # anomalies (red dots)\n",
        "                if feat in anomalies:\n",
        "                    anom_x, anom_y = anomalies[feat]\n",
        "                    label = \"Anomaly\" if not anomaly_plotted_label else None\n",
        "                    ax_i.scatter(anom_x, anom_y, color=\"red\", s=50, zorder=5, label=label)\n",
        "                    if not anomaly_plotted_label:\n",
        "                        anomaly_plotted_label = True\n",
        "\n",
        "                ax_i.set_ylabel(feat, color=color, fontsize=12, fontweight=\"bold\")\n",
        "                ax_i.tick_params(axis=\"y\", labelcolor=color)\n",
        "\n",
        "            ax_feat.set_title(user_title, fontweight='bold')\n",
        "            ax_feat.grid(True)\n",
        "            ax_feat.tick_params(axis='x', labelbottom=True)\n",
        "\n",
        "            lines, labels = [], []\n",
        "            for a in axes_list:\n",
        "                l, lb = a.get_legend_handles_labels()\n",
        "                lines += l\n",
        "                labels += lb\n",
        "            if lines:\n",
        "                ax_feat.legend(lines, labels, loc='best')\n",
        "\n",
        "        # Flare heatmap\n",
        "        heat_flare = np.full((1, n_dates), np.nan)\n",
        "        heat_flare[0, :] = flare_numeric\n",
        "\n",
        "        ax_flare.imshow(\n",
        "            heat_flare,\n",
        "            aspect=\"auto\",\n",
        "            interpolation=\"none\",\n",
        "            origin=\"lower\",\n",
        "            extent=[dates_num.min() - .5, dates_num.max() + .5, -0.5, 0.5],\n",
        "            cmap=cmap_symptom,\n",
        "            norm=norm_symptom\n",
        "        )\n",
        "        ax_flare.set_yticks([0])\n",
        "        ax_flare.set_yticklabels([\"rate_as_flare\"], fontsize=11)\n",
        "        ax_flare.set_title('Subjective Flare Assessment (\"Yes\" / \"Unsure\" / \"No\")', fontsize=12)\n",
        "        ax_flare.tick_params(axis='x', labelbottom=False)\n",
        "\n",
        "    # ---------- STACKED ---------\n",
        "    else:\n",
        "        n_feat = len(features)\n",
        "        if n_feat == 0:\n",
        "            n_feat = 1\n",
        "\n",
        "        feature_height = 2.5\n",
        "        feature_block_height = feature_height * n_feat\n",
        "        total_height = heat_height + deg_height + feature_block_height + flare_height\n",
        "\n",
        "        n_rows = 3 + (len(features) if len(features) > 0 else 1)\n",
        "\n",
        "        if len(features) > 0:\n",
        "            feature_heights = [feature_height] * len(features)\n",
        "        else:\n",
        "            feature_heights = [feature_height]\n",
        "\n",
        "        height_ratios = [heat_height, deg_height] + feature_heights + [flare_height]\n",
        "\n",
        "        fig, axes = plt.subplots(\n",
        "            n_rows, 1,\n",
        "            sharex=True,\n",
        "            figsize=(16, total_height),\n",
        "            gridspec_kw={\"height_ratios\": height_ratios}\n",
        "        )\n",
        "\n",
        "        ax_heat = axes[0]\n",
        "        ax_deg = axes[1]\n",
        "        feature_axes = axes[2:-1]\n",
        "        ax_flare = axes[-1]\n",
        "\n",
        "        # Symptom presence\n",
        "        if n_sym > 0:\n",
        "            heat_presence = np.full((n_sym, n_dates), np.nan)\n",
        "            for col, items in enumerate(parsed_symptoms_per_row):\n",
        "                if items is None:\n",
        "                    continue\n",
        "                heat_presence[:, col] = 0.0\n",
        "                for s in items:\n",
        "                    if s in sym_idx:\n",
        "                        heat_presence[sym_idx[s], col] = 1.0\n",
        "\n",
        "            if smooth and w > 1:\n",
        "                presence_df = pd.DataFrame(\n",
        "                    heat_presence.T,\n",
        "                    index=df.index,\n",
        "                    columns=all_symptoms\n",
        "                )\n",
        "                presence_df = presence_df.rolling(window=w, min_periods=1).mean()\n",
        "                heat_presence = presence_df.to_numpy().T\n",
        "\n",
        "            ax_heat.imshow(\n",
        "                heat_presence,\n",
        "                aspect=\"auto\",\n",
        "                interpolation=\"none\",\n",
        "                origin=\"lower\",\n",
        "                extent=[dates_num.min() - .5, dates_num.max() + .5, -0.5, n_sym - .5],\n",
        "                cmap=cmap_symptom_presence,\n",
        "                norm=norm_symptom_presence\n",
        "            )\n",
        "            ax_heat.set_yticks(range(n_sym))\n",
        "            ax_heat.set_yticklabels(all_symptoms, fontsize=11)\n",
        "            ax_heat.set_title(\"Symptoms (True / False)\")\n",
        "            ax_heat.tick_params(axis='x', labelbottom=False)\n",
        "\n",
        "        else:\n",
        "            ax_heat.text(0.5, 0.5, \"No selected symptoms\",\n",
        "                         ha='center', va='center', transform=ax_heat.transAxes)\n",
        "            ax_heat.set_yticks([])\n",
        "\n",
        "        # symptom_deg\n",
        "        heat_deg = np.full((1, n_dates), np.nan)\n",
        "        heat_deg[0, :] = deg_series.values\n",
        "\n",
        "        ax_deg.imshow(\n",
        "            heat_deg,\n",
        "            aspect=\"auto\",\n",
        "            interpolation=\"none\",\n",
        "            origin=\"lower\",\n",
        "            extent=[dates_num.min() - .5, dates_num.max() + .5, -0.5, 0.5],\n",
        "            cmap=cmap_symptom,\n",
        "            norm=norm_symptom\n",
        "        )\n",
        "        ax_deg.set_yticks([0])\n",
        "        ax_deg.set_yticklabels([\"symptom_deg\"], fontsize=11)\n",
        "        ax_deg.set_title(\"Symptom Degree (0-5)\")\n",
        "        ax_deg.tick_params(axis='x', labelbottom=False)\n",
        "\n",
        "        # feature stacked plots (single color for all features)\n",
        "        if data is None or len(features) == 0:\n",
        "            ax_feat = feature_axes[0]\n",
        "            ax_feat.text(0.5, 0.5, \"No feature selected\",\n",
        "                         ha='center', va='center', transform=ax_feat.transAxes)\n",
        "            ax_feat.set_yticks([])\n",
        "        else:\n",
        "            base_color = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0]\n",
        "\n",
        "            for i, (ax_f, feat) in enumerate(zip(feature_axes, features)):\n",
        "                x = data[\"date\"]\n",
        "                y = data[feat]\n",
        "\n",
        "                # Variability band when smoothing + checkbox enabled\n",
        "                if (\n",
        "                    smooth and w > 1 and\n",
        "                    variability_band and\n",
        "                    data_std is not None and\n",
        "                    feat in data_std.columns\n",
        "                ):\n",
        "                    y_std = data_std[feat]\n",
        "                    ax_f.fill_between(\n",
        "                        x,\n",
        "                        y - variability_std * y_std,\n",
        "                        y + variability_std * y_std,\n",
        "                        alpha=0.15,\n",
        "                        color=base_color\n",
        "                    )\n",
        "\n",
        "                if plot_style in (\"line\", \"line_scatter\"):\n",
        "                    ax_f.plot(x, y, color=base_color)\n",
        "                if plot_style in (\"scatter\", \"line_scatter\"):\n",
        "                    ax_f.scatter(x, y, color=base_color, s=20)\n",
        "\n",
        "                # anomalies (red dots)\n",
        "                if feat in anomalies:\n",
        "                    anom_x, anom_y = anomalies[feat]\n",
        "                    ax_f.scatter(anom_x, anom_y, color=\"red\", s=50, zorder=5)\n",
        "\n",
        "                ax_f.set_ylabel(feat, fontsize=12, fontweight=\"bold\")\n",
        "                ax_f.grid(True)\n",
        "\n",
        "                if i == 0:\n",
        "                    ax_f.set_title(user_title, fontweight='bold')\n",
        "\n",
        "                if i < len(feature_axes) - 1:\n",
        "                    ax_f.tick_params(axis='x', labelbottom=False)\n",
        "\n",
        "        # flare heatmap\n",
        "        heat_flare = np.full((1, n_dates), np.nan)\n",
        "        heat_flare[0, :] = flare_numeric\n",
        "\n",
        "        ax_flare.imshow(\n",
        "            heat_flare,\n",
        "            aspect=\"auto\",\n",
        "            interpolation=\"none\",\n",
        "            origin=\"lower\",\n",
        "            extent=[dates_num.min() - .5, dates_num.max() + .5, -0.5, 0.5],\n",
        "            cmap=cmap_symptom,\n",
        "            norm=norm_symptom\n",
        "        )\n",
        "        ax_flare.set_yticks([0])\n",
        "        ax_flare.set_yticklabels([\"rate_as_flare\"], fontsize=11)\n",
        "        ax_flare.set_title('Subjective Flare Assessment (\"Yes\" / \"Unsure\" / \"No\")', fontsize=12)\n",
        "        ax_flare.tick_params(axis='x', labelbottom=True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# Connect interactive output\n",
        "# ----------------------------\n",
        "out = interactive_output(\n",
        "    plot_user,\n",
        "    dict(\n",
        "        user_id=user_selector,\n",
        "        features=feature_selector,\n",
        "        smooth=smooth_checkbox,\n",
        "        window=smooth_window,\n",
        "        layout_mode=layout_selector,\n",
        "        plot_style=plot_style_selector,\n",
        "        anomaly_method=anomaly_method_selector,\n",
        "        contamination=contamination_text,\n",
        "        std_factor=std_factor_text,\n",
        "        obs_window_days=obs_window_widget,\n",
        "        det_window_days=det_window_widget,\n",
        "        min_obs=min_obs_widget,\n",
        "        alpha=alpha_widget,\n",
        "        short_term=short_term_widget,\n",
        "        alarm_fraction=alarm_fraction_widget,\n",
        "        detection_logic=detection_logic_widget,\n",
        "        variability_band=variability_checkbox,\n",
        "        variability_std=variability_std_text\n",
        "    )\n",
        ")\n",
        "\n",
        "display(\n",
        "    VBox([\n",
        "        HBox([\n",
        "            VBox([\n",
        "                user_selector,\n",
        "                data_type_filter,\n",
        "                min_days_filter\n",
        "            ]),\n",
        "            feature_selector,\n",
        "            VBox([\n",
        "                smooth_checkbox,\n",
        "                smooth_window,\n",
        "                variability_checkbox,\n",
        "                variability_std_text,\n",
        "                layout_selector,\n",
        "                plot_style_selector\n",
        "            ]),\n",
        "            VBox([\n",
        "                anomaly_method_selector,\n",
        "                obs_window_widget,\n",
        "                det_window_widget,\n",
        "                min_obs_widget,\n",
        "                elliptic_params_box,\n",
        "                std_params_box,\n",
        "                cusum_params_box\n",
        "            ])\n",
        "        ]),\n",
        "        out\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "xHnCUG3hwaQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}