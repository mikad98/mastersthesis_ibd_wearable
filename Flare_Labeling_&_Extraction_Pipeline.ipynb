{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCsJG9MrA82EOan1lZvwgA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "lEzE20WhX4BA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtpGgUFCXqZK",
        "outputId": "0b410bf2-6992-4218-f8b0-3c5eebaec588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "import ast\n",
        "from ast import literal_eval\n",
        "from datetime import date\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline"
      ],
      "metadata": {
        "id": "pe3Ga0sZYWUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlarePipeline:\n",
        "    def __init__(\n",
        "        self,\n",
        "        flare_threshold: float = 2.5,\n",
        "        gap_fill_max: int = 4,\n",
        "        island_min_len: int = 14,\n",
        "        smoothing_window: int = 7,\n",
        "        flare_merge_gap: int = 7,\n",
        "        min_flare_length: int = 3\n",
        "    ):\n",
        "        self.flare_threshold = flare_threshold\n",
        "        self.gap_fill_max = gap_fill_max\n",
        "        self.island_min_len = island_min_len\n",
        "        self.smoothing_window = smoothing_window\n",
        "        self.flare_merge_gap = flare_merge_gap\n",
        "        self.min_flare_length = min_flare_length\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # --- Step 1: Data continuity + gap filling ---\n",
        "    # ------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def _fill_user_data(group: pd.DataFrame) -> pd.DataFrame:\n",
        "        user_id = group['user_id'].iloc[0]\n",
        "        group = group.copy()\n",
        "        group['date'] = pd.to_datetime(group['date'])\n",
        "\n",
        "        if group['date'].nunique() <= 1:\n",
        "            return group\n",
        "\n",
        "        full_dates = pd.date_range(group['date'].min(), group['date'].max(), freq='D')\n",
        "        full_df = pd.DataFrame({'user_id': user_id, 'date': full_dates})\n",
        "        merged = pd.merge(full_df, group, on=['user_id', 'date'], how='left')\n",
        "        return merged\n",
        "\n",
        "    def _fill_small_gaps(self, df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
        "        df = df.copy()\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df = df.drop_duplicates(subset=['user_id', 'date'])\n",
        "\n",
        "        filled = []\n",
        "        for user, group in df.groupby('user_id'):\n",
        "            group = group.sort_values('date').set_index('date')\n",
        "            group = group[~group.index.duplicated(keep='first')]\n",
        "\n",
        "            full_range = pd.date_range(group.index.min(), group.index.max(), freq='D')\n",
        "            group = group.reindex(full_range)\n",
        "            group['user_id'] = user\n",
        "\n",
        "            col_idx = group.columns.get_loc(col)\n",
        "            i = 0\n",
        "            while i < len(group):\n",
        "                if pd.isna(group.iloc[i, col_idx]):\n",
        "                    start = i\n",
        "                    while i < len(group) and pd.isna(group.iloc[i, col_idx]):\n",
        "                        i += 1\n",
        "                    end = i\n",
        "                    gap_len = end - start\n",
        "\n",
        "                    if gap_len <= self.gap_fill_max and start > 0 and end < len(group):\n",
        "                        if gap_len == 1:\n",
        "                            group.iloc[start, col_idx] = group.iloc[start-1, col_idx]\n",
        "                        elif gap_len == 2:\n",
        "                            group.iloc[start, col_idx] = group.iloc[start-1, col_idx]\n",
        "                            group.iloc[start+1, col_idx] = group.iloc[end, col_idx]\n",
        "                        elif gap_len == 3:\n",
        "                            group.iloc[start:start+2, col_idx] = group.iloc[start-1, col_idx]\n",
        "                            group.iloc[start+2, col_idx] = group.iloc[end, col_idx]\n",
        "                        elif gap_len == 4:\n",
        "                            group.iloc[start:start+2, col_idx] = group.iloc[start-1, col_idx]\n",
        "                            group.iloc[start+2:end, col_idx] = group.iloc[end, col_idx]\n",
        "                else:\n",
        "                    i += 1\n",
        "\n",
        "            filled.append(group)\n",
        "\n",
        "        return (\n",
        "            pd.concat(filled)\n",
        "            .reset_index()\n",
        "            .rename(columns={'index': 'date'})\n",
        "        )\n",
        "\n",
        "    def _remove_small_islands(self, df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
        "        result = []\n",
        "        for user, group in df.groupby('user_id'):\n",
        "            group = group.sort_values('date').reset_index(drop=True)\n",
        "            mask = group[col].notna().astype(int)\n",
        "            streak_id = (mask.ne(mask.shift())).cumsum()\n",
        "\n",
        "            for _, sub in group.groupby(streak_id):\n",
        "                if sub[col].notna().all() and len(sub) < self.island_min_len:\n",
        "                    wipe_cols = [c for c in group.columns if c not in ['user_id', 'date']]\n",
        "                    group.loc[sub.index, wipe_cols] = pd.NA\n",
        "            result.append(group)\n",
        "        return pd.concat(result).reset_index(drop=True)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # --- Step 2: Smoothing ---\n",
        "    # ------------------------------------------------------------------\n",
        "    def _smooth_rate_as_flare(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        df = df.copy()\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df = df.sort_values(['user_id', 'date'])\n",
        "\n",
        "        def rolling_mode(series: pd.Series) -> pd.Series:\n",
        "            values = []\n",
        "            for i in range(len(series)):\n",
        "                start = max(0, i - self.smoothing_window + 1)\n",
        "                window_vals = series[start:i+1].dropna()\n",
        "                if len(window_vals) > 0:\n",
        "                    values.append(Counter(window_vals).most_common(1)[0][0])\n",
        "                else:\n",
        "                    values.append(pd.NA)\n",
        "            return pd.Series(values, index=series.index)\n",
        "\n",
        "        df['rate_as_flare'] = (\n",
        "            df.groupby('user_id')['rate_as_flare']\n",
        "              .transform(rolling_mode)\n",
        "        )\n",
        "        return df\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # --- Step 3: Flare Annotation ---\n",
        "    # ------------------------------------------------------------------\n",
        "    def _connect_flares(self, df: pd.DataFrame, flare_col: str) -> pd.DataFrame:\n",
        "        df = df.copy()\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "        filled = []\n",
        "        for user, group in df.groupby(\"user_id\"):\n",
        "            group = group.sort_values(\"date\").reset_index(drop=True)\n",
        "            flare_idx = group.index[group[flare_col] == True].to_list()\n",
        "\n",
        "            if not flare_idx:\n",
        "                filled.append(group)\n",
        "                continue\n",
        "\n",
        "            for i in range(len(flare_idx) - 1):\n",
        "                start = group.loc[flare_idx[i], 'date']\n",
        "                end = group.loc[flare_idx[i + 1], 'date']\n",
        "                gap = (end - start).days\n",
        "                if gap < self.flare_merge_gap:\n",
        "                    mask = (group['date'] > start) & (group['date'] < end)\n",
        "                    group.loc[mask, flare_col] = True\n",
        "            filled.append(group)\n",
        "        return pd.concat(filled).reset_index(drop=True)\n",
        "\n",
        "    def _remove_short_flares(self, df: pd.DataFrame, flare_col: str) -> pd.DataFrame:\n",
        "        result = []\n",
        "        for user, group in df.groupby(\"user_id\"):\n",
        "            group = group.sort_values(\"date\").copy()\n",
        "            group['block'] = (group[flare_col] != group[flare_col].shift()).cumsum()\n",
        "            block_sizes = group.groupby('block')[flare_col].transform('size')\n",
        "\n",
        "            group.loc[(group[flare_col] == True) & (block_sizes <= self.min_flare_length), flare_col] = pd.NA\n",
        "            group = group.drop(columns='block')\n",
        "            result.append(group)\n",
        "        return pd.concat(result).reset_index(drop=True)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # --- Step 4: Flare Grouping & Summary ---\n",
        "    # ------------------------------------------------------------------\n",
        "    @staticmethod\n",
        "    def _assign_flare_groups(df: pd.DataFrame, flare_col: str) -> pd.DataFrame:\n",
        "        df = df.sort_values(\"date\").copy()\n",
        "        df[\"flare_group\"] = (\n",
        "            (df[flare_col] == True) & ((df[flare_col].shift(fill_value=False) != True) |\n",
        "                                       (df[\"date\"].diff().dt.days > 1))\n",
        "        ).cumsum()\n",
        "        df.loc[df[flare_col] != True, \"flare_group\"] = pd.NA\n",
        "        return df\n",
        "\n",
        "    def _process_flares(self, df: pd.DataFrame, objective: pd.DataFrame, flare_col: str) -> pd.DataFrame:\n",
        "        df = (\n",
        "            df.groupby(\"user_id\", group_keys=False)\n",
        "              .apply(self._assign_flare_groups, flare_col=flare_col)\n",
        "        )\n",
        "\n",
        "        flares = (\n",
        "            df.dropna(subset=[\"flare_group\"])\n",
        "              .groupby([\"user_id\", \"flare_group\"])\n",
        "              .agg(\n",
        "                  date_flare_onset=(\"date\", \"min\"),\n",
        "                  date_flare_end=(\"date\", \"max\"),\n",
        "                  flare_length=(\"date\", lambda x: (x.max() - x.min()).days + 1),\n",
        "              )\n",
        "              .reset_index()\n",
        "        )\n",
        "\n",
        "        objective_cols = [\n",
        "            'sleep_eff', 'dur_asleep', 'dur_REM', 'REM_pct', 'dur_deep', 'deep_pct', 'dur_light',\n",
        "            'light_pct', 'dur_awake', 'hrv_rmssd', 'avg_hrv_rmssd', 'std_rmssd', 'cv_rmssd',\n",
        "            'min_rmssd', 'max_rmssd', 'range_rmssd', 'slope_rmssd', 'hrv_sdnn', 'avg_hrv_sdnn',\n",
        "            'avg_bpm', 'rhr', 'avg_SpO2', 'avg_breaths'\n",
        "        ]\n",
        "\n",
        "        flare_records = []\n",
        "        for _, row in flares.iterrows():\n",
        "            mask = (\n",
        "                (objective[\"user_id\"] == row[\"user_id\"]) &\n",
        "                (objective[\"date\"].between(row[\"date_flare_onset\"], row[\"date_flare_end\"]))\n",
        "            )\n",
        "            sub_obj = objective.loc[mask, objective_cols]\n",
        "            avg_values = sub_obj.mean(numeric_only=True)\n",
        "\n",
        "            record = {\n",
        "                \"user_id\": row[\"user_id\"],\n",
        "                \"date_flare_onset\": row[\"date_flare_onset\"],\n",
        "                \"date_flare_end\": row[\"date_flare_end\"],\n",
        "                \"flare_length\": row[\"flare_length\"],\n",
        "                **avg_values.to_dict()\n",
        "            }\n",
        "            flare_records.append(record)\n",
        "\n",
        "        return pd.DataFrame(flare_records)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # --- Main runner ---\n",
        "    # ------------------------------------------------------------------\n",
        "    def run(self, subjective: pd.DataFrame, objective: pd.DataFrame):\n",
        "        subjective = subjective.groupby('user_id', group_keys=False).apply(self._fill_user_data)\n",
        "        objective = objective.groupby('user_id', group_keys=False).apply(self._fill_user_data)\n",
        "\n",
        "        subjective = self._fill_small_gaps(subjective, \"symptom_deg\")\n",
        "        subjective = self._fill_small_gaps(subjective, \"rate_as_flare\")\n",
        "\n",
        "        subjective = self._remove_small_islands(subjective, col=\"symptom_deg\")\n",
        "        subjective = self._remove_small_islands(subjective, col=\"rate_as_flare\")\n",
        "\n",
        "        subjective['symptom_deg'] = (\n",
        "            subjective.groupby('user_id')['symptom_deg']\n",
        "            .transform(lambda x: x.rolling(window=self.smoothing_window, min_periods=1).mean())\n",
        "        )\n",
        "        subjective = self._smooth_rate_as_flare(subjective)\n",
        "\n",
        "        subjective['symptom_flare'] = np.where(\n",
        "            subjective['symptom_deg'].notna(),\n",
        "            subjective['symptom_deg'] >= self.flare_threshold,\n",
        "            pd.NA\n",
        "        )\n",
        "        subjective['flare'] = np.where(\n",
        "            subjective['rate_as_flare'].notna(),\n",
        "            subjective['rate_as_flare'] == \"Yes\",\n",
        "            pd.NA\n",
        "        )\n",
        "\n",
        "        subjective = self._connect_flares(subjective, flare_col=\"symptom_flare\")\n",
        "        subjective = self._connect_flares(subjective, flare_col=\"flare\")\n",
        "\n",
        "        subjective = self._remove_short_flares(subjective, flare_col=\"flare\")\n",
        "        subjective = self._remove_short_flares(subjective, flare_col=\"symptom_flare\")\n",
        "\n",
        "        subjective = subjective.sort_values([\"user_id\", \"date\"])\n",
        "        objective = objective.sort_values([\"user_id\", \"date\"])\n",
        "\n",
        "        summary_symptom_flares = self._process_flares(subjective, objective, flare_col=\"symptom_flare\")\n",
        "        summary_regular_flares = self._process_flares(subjective, objective, flare_col=\"flare\")\n",
        "\n",
        "        return subjective, objective, summary_symptom_flares, summary_regular_flares"
      ],
      "metadata": {
        "id": "dDgKyla2X85B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load data\n",
        "subjective = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/subjective.csv')\n",
        "objective = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/objective.csv')\n",
        "\n",
        "# Make sure date column is datetime\n",
        "objective['date'] = pd.to_datetime(objective['date'])\n",
        "subjective['date'] = pd.to_datetime(subjective['date'])\n",
        "\n",
        "# 2. Initialize pipeline (with default parameters, or override if needed)\n",
        "pipeline = FlarePipeline(\n",
        "    flare_threshold=2.5,   # threshold for symptom_deg\n",
        "    gap_fill_max=4,        # max gap length to fill\n",
        "    island_min_len=14,     # min streak length to keep\n",
        "    smoothing_window=7,    # smoothing window\n",
        "    flare_merge_gap=7,     # max gap to merge flares\n",
        "    min_flare_length=3     # remove flares shorter than this\n",
        ")\n",
        "\n",
        "# 3. Run pipeline\n",
        "subjective_proc, objective_proc, summary_symptom_flares, summary_regular_flares = pipeline.run(subjective, objective)"
      ],
      "metadata": {
        "id": "AXjYL0wOYVFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Data"
      ],
      "metadata": {
        "id": "fnNMvJGhOjgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_symptom_flares.to_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/summary_symptom_flares.csv', index=False)\n",
        "summary_regular_flares.to_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/summary_regular_flares.csv', index=False)\n",
        "subjective_proc.to_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/subjective_flare_annotated.csv', index=False)"
      ],
      "metadata": {
        "id": "eMiKDMGuOjov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plots"
      ],
      "metadata": {
        "id": "fgFiQQZAzAWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_user_data(\n",
        "    df: pd.DataFrame,\n",
        "    value_col: str,\n",
        "    max_users: int = 50,\n",
        "    spacing_between_users: float = 3,\n",
        "    cmap=None,\n",
        "    norm=None,\n",
        "    categorical_map: dict = None,\n",
        "    markersize: int = 2\n",
        "):\n",
        "\n",
        "    # Sort users by number of records\n",
        "    user_counts = df['user_id'].value_counts(ascending=True)\n",
        "    sorted_users = user_counts.index.tolist()[-max_users:]\n",
        "\n",
        "    height = len(sorted_users) * 0.18\n",
        "    width = 14\n",
        "    fig, ax = plt.subplots(figsize=(width, height))\n",
        "\n",
        "    for i, user in enumerate(sorted_users):\n",
        "        user_data = df[df['user_id'] == user].reset_index(drop=True)\n",
        "        base_y = i * spacing_between_users\n",
        "\n",
        "        for j, row in user_data.iterrows():\n",
        "            val = row[value_col]\n",
        "\n",
        "            # Determine color\n",
        "            if pd.isna(val):\n",
        "                color = (0, 0, 0, 0)  # transparent for NaN\n",
        "            elif categorical_map is not None:\n",
        "                color = categorical_map.get(val, (0, 0, 0, 0))\n",
        "            elif cmap is not None and norm is not None:\n",
        "                color = cmap(norm(val))\n",
        "            else:\n",
        "                color = (0, 0, 0, 1)  # fallback black\n",
        "\n",
        "            ax.plot(j, base_y, 'o', color=color, markersize=markersize)\n",
        "\n",
        "    # Y-axis labels = user IDs\n",
        "    ytick_positions = [i * spacing_between_users for i in range(len(sorted_users))]\n",
        "    ax.set_yticks(ytick_positions)\n",
        "    ax.set_yticklabels(sorted_users, fontsize=5)\n",
        "\n",
        "    ax.set_ylim(-2, (len(sorted_users) - 1) * spacing_between_users + 2)\n",
        "    ax.set_xlabel(\"Days since first record\")\n",
        "    ax.set_ylabel(\"User ID\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iRX2xmkdOfJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plots"
      ],
      "metadata": {
        "id": "PssuLPer6Z5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_symptom = mcolors.Normalize(vmin=0, vmax=5)\n",
        "cmap_symptom = cm.get_cmap('RdYlGn_r')\n",
        "\n",
        "plot_user_data(subjective_proc, value_col='symptom_deg', cmap=cmap_symptom, norm=norm_symptom)"
      ],
      "metadata": {
        "id": "-9jnP4agazM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flare_color = cm.get_cmap('RdYlGn_r')(mcolors.Normalize(vmin=0, vmax=5)(4))\n",
        "\n",
        "plot_user_data(subjective_proc, value_col='symptom_flare', categorical_map={True: flare_color, False: \"lightgray\"})"
      ],
      "metadata": {
        "id": "yKr7hNnIzFMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_symptom = mcolors.Normalize(vmin=0, vmax=5)\n",
        "cmap_symptom = cm.get_cmap('RdYlGn_r')\n",
        "\n",
        "categorical_map = {\"Yes\": cmap_symptom(norm_symptom(4)), \"No\": cmap_symptom(norm_symptom(1)), \"Unsure\": cmap_symptom(norm_symptom(3)), np.nan: (0,0,0,0)}\n",
        "\n",
        "plot_user_data(subjective_proc, value_col='rate_as_flare', categorical_map=categorical_map)"
      ],
      "metadata": {
        "id": "b_EXi28tzYHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flare_color = cm.get_cmap('RdYlGn_r')(mcolors.Normalize(vmin=0, vmax=5)(4))\n",
        "\n",
        "plot_user_data(subjective_proc, value_col='flare', categorical_map={True: flare_color, False: \"lightgray\"})"
      ],
      "metadata": {
        "id": "Re7cPZT8zrZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison to Hirten: symptom_deg Flare"
      ],
      "metadata": {
        "id": "BKucN05XKfaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flare_color = cm.get_cmap('RdYlGn_r')(mcolors.Normalize(vmin=0, vmax=5)(4))\n",
        "\n",
        "plot_user_data(subjective_proc, value_col='symptom_flare', max_users = 300, spacing_between_users = 2, markersize = 5, categorical_map={True: flare_color, False: \"lightgray\"})"
      ],
      "metadata": {
        "id": "2GuA2_bmIQZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison to Hirten: rate_as_flare Flare"
      ],
      "metadata": {
        "id": "r1j6Pc18Kkk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flare_color = cm.get_cmap('RdYlGn_r')(mcolors.Normalize(vmin=0, vmax=5)(4))\n",
        "\n",
        "plot_user_data(subjective_proc, value_col='flare', max_users = 300, spacing_between_users = 2, markersize = 5,categorical_map={True: flare_color, False: \"lightgray\"})"
      ],
      "metadata": {
        "id": "I6CRnNh0HpZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}