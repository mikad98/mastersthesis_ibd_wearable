{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNmdIU8+Z0YzidhFqvWq+2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "5dC2lx7xHB3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1HB3j5LG7Nh",
        "outputId": "d1f90f35-7768-4e5c-92f0-033182530d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.patches as mpatches\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "import ast\n",
        "import re\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "from ast import literal_eval\n",
        "from statsmodels.regression.mixed_linear_model import MixedLM\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2\n",
        "from scipy.stats import t\n",
        "from datetime import date\n",
        "from patsy import dmatrix\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "drive.mount('/content/drive')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Prepare Data\n"
      ],
      "metadata": {
        "id": "jHiytSP5ICdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Data ---\n",
        "summary_symptom_flares = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/summary_symptom_flares.csv')\n",
        "summary_regular_flares = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/summary_regular_flares.csv')\n",
        "subjective_flare_annotated = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/subjective_flare_annotated.csv')\n",
        "objective = pd.read_csv('/content/drive/My Drive/coreway_ml/Thesis - Mika/objective.csv')\n",
        "\n",
        "# --- Keep relevant columns ---\n",
        "summary_symptom_flares = summary_symptom_flares[['user_id', 'date_flare_onset', 'date_flare_end']]\n",
        "summary_regular_flares = summary_regular_flares[['user_id', 'date_flare_onset', 'date_flare_end']]\n",
        "subjective_flare_annotated = subjective_flare_annotated[[\"user_id\", \"date\", \"gender\", \"age\", \"diagnosis\", \"symptom_flare\", \"flare\"]]\n",
        "objective = objective[[\"user_id\", \"date\", \"provider\", \"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"]]\n",
        "\n",
        "# --- Merge datasets ---\n",
        "merged = pd.merge(subjective_flare_annotated, objective, on=[\"user_id\", \"date\"], how=\"inner\")"
      ],
      "metadata": {
        "id": "jS8nafAHIhxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Association Analysis"
      ],
      "metadata": {
        "id": "yQ4qCmRB-MMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_emm(mixed_model, df, predictor):\n",
        "\n",
        "    levels = df[predictor].unique()\n",
        "    emms = []\n",
        "    ses = []\n",
        "\n",
        "    for lvl in levels:\n",
        "\n",
        "        df_ref = df.copy()\n",
        "        df_ref[predictor] = lvl\n",
        "\n",
        "        # Build design matrix for the full dataset at this level\n",
        "        exog_ref = dmatrix(mixed_model.model.data.design_info.builder, df_ref, return_type=\"dataframe\")\n",
        "\n",
        "        # Predicted values\n",
        "        yhat = exog_ref @ mixed_model.fe_params.values\n",
        "\n",
        "        # Average across population\n",
        "        emm = yhat.mean()\n",
        "        emms.append(emm)\n",
        "\n",
        "        # Variance of the mean prediction\n",
        "        cov_fe = mixed_model.cov_params()\n",
        "        cov_fe = cov_fe.loc[exog_ref.columns, exog_ref.columns]\n",
        "        mean_design = exog_ref.mean(axis=0).values.reshape(1, -1)\n",
        "        var_emm = mean_design @ cov_fe.values @ mean_design.T\n",
        "        ses.append(np.sqrt(var_emm.item()))\n",
        "\n",
        "    # Compute confidence intervals\n",
        "    tval = t.ppf(0.975, mixed_model.df_resid)\n",
        "    ci_lower = np.array(emms) - tval * np.array(ses)\n",
        "    ci_upper = np.array(emms) + tval * np.array(ses)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        predictor: levels,\n",
        "        \"EMM\": emms,\n",
        "        \"SE\": ses,\n",
        "        \"CI_lower\": ci_lower,\n",
        "        \"CI_upper\": ci_upper\n",
        "    })\n",
        "\n",
        "# --- Define metrics & predictors ---\n",
        "sleep_metrics = [\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"]\n",
        "flare_predictors = [\"symptom_flare\", \"flare\"]\n",
        "\n",
        "# --- Run models ---\n",
        "results = {}\n",
        "\n",
        "for metric in sleep_metrics:\n",
        "\n",
        "    for predictor in flare_predictors:\n",
        "\n",
        "        formula = f\"{metric} ~ gender + age + {predictor} + provider\"\n",
        "        df_model = merged[[\"user_id\", metric, \"gender\", \"age\", predictor, \"provider\"]].dropna()\n",
        "\n",
        "        # --- Homogeneous variance model ---\n",
        "        m1 = smf.mixedlm(formula, data=df_model, groups=df_model[\"user_id\"])\n",
        "        res1 = m1.fit(reml=False)\n",
        "\n",
        "        # --- Heterogeneous variance model ---\n",
        "        m2 = smf.mixedlm(formula, data=df_model, groups=df_model[\"user_id\"], vc_formula={predictor: f\"C({predictor})\"})\n",
        "        res2 = m2.fit(reml=False)\n",
        "\n",
        "        # --- Likelihood ratio test ---\n",
        "        lr_stat = 2 * (res2.llf - res1.llf)\n",
        "        df_diff = 1\n",
        "        p_value = chi2.sf(lr_stat, df_diff)\n",
        "\n",
        "        # Select final model\n",
        "        if (p_value < 0.05) or (res2.aic < res1.aic):\n",
        "            final_model = res2\n",
        "            model_type = \"heterogeneous\"\n",
        "        else:\n",
        "            final_model = res1\n",
        "            model_type = \"homogeneous\"\n",
        "\n",
        "        marginal_means = compute_emm(final_model, df_model, predictor)\n",
        "\n",
        "        # Store in dict\n",
        "        key = f\"{metric} ~ {predictor}\"\n",
        "        results[key] = {\n",
        "            \"final_model_type\": model_type,\n",
        "            \"AIC_homogeneous\": res1.aic,\n",
        "            \"AIC_heterogeneous\": res2.aic,\n",
        "            \"LRT_stat\": lr_stat,\n",
        "            \"LRT_df\": df_diff,\n",
        "            \"LRT_p\": p_value,\n",
        "            \"summary\": final_model.summary(),\n",
        "            \"marginal_means\": marginal_means,\n",
        "            \"final_model\": final_model\n",
        "        }\n",
        "\n",
        "# --- Print results ---\n",
        "for key, res in results.items():\n",
        "    print(\"=\"*100)\n",
        "    print(\"\\n\")\n",
        "    print(f\"Model: {key}\")\n",
        "    print(f\"Final model chosen: {res['final_model_type']}\")\n",
        "    print(f\"AIC (homogeneous): {res['AIC_homogeneous']:.2f}, \"\n",
        "          f\"AIC (heterogeneous): {res['AIC_heterogeneous']:.2f}\")\n",
        "    print(f\"LRT: stat={res['LRT_stat']:.3f}, df={res['LRT_df']}, p={res['LRT_p']:.4f}\")\n",
        "    print(res[\"summary\"])\n",
        "    print(\"\\n--- Marginal means (95% CI) ---\")\n",
        "    print(res[\"marginal_means\"])\n",
        "    print(\"\\n\")\n",
        "\n",
        "#  --- EMM summary table ---\n",
        "summary_rows = []\n",
        "\n",
        "for key, res in results.items():\n",
        "    metric, predictor = key.split(\" ~ \")\n",
        "\n",
        "    # Extract marginal means\n",
        "    mm = res[\"marginal_means\"]\n",
        "    mm_dict = {f\"{row[predictor]}\": f\"{row['EMM']:.3f} ({row['SE']:.3f})\"\n",
        "               for _, row in mm.iterrows()}\n",
        "\n",
        "    # Extract p-value for predictor (fix!)\n",
        "    predictor_terms = [name for name in res[\"final_model\"].pvalues.index\n",
        "                       if name.startswith(predictor)]\n",
        "\n",
        "    if len(predictor_terms) == 1:\n",
        "        pval = res[\"final_model\"].pvalues[predictor_terms[0]]\n",
        "    elif len(predictor_terms) > 1:\n",
        "        # placeholder: choose smallest p-value across levels\n",
        "        pval = res[\"final_model\"].pvalues[predictor_terms].max()\n",
        "    else:\n",
        "        pval = None\n",
        "\n",
        "    row = {\n",
        "        \"metric\": metric,\n",
        "        \"predictor\": predictor,\n",
        "        **mm_dict,\n",
        "        \"p_value\": pval\n",
        "    }\n",
        "    summary_rows.append(row)\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "\n",
        "summary_df"
      ],
      "metadata": {
        "id": "U9XJ85pLzD-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_mean_se(cell):\n",
        "    \"\"\"\n",
        "    Parse strings like '20.109 (0.503)' -> (20.109, 0.503)\n",
        "    \"\"\"\n",
        "    if pd.isna(cell):\n",
        "        return np.nan, np.nan\n",
        "    m = re.match(r\"\\s*([-+]?\\d*\\.?\\d+)\\s*\\(\\s*([-+]?\\d*\\.?\\d+)\\s*\\)\\s*\", str(cell))\n",
        "    if m:\n",
        "        return float(m.group(1)), float(m.group(2))\n",
        "    # if already numeric, try to handle gracefully\n",
        "    try:\n",
        "        return float(cell), np.nan\n",
        "    except Exception:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def stars_from_p(p):\n",
        "    if p < 0.01:\n",
        "        return \"**\"\n",
        "    if p < 0.05:\n",
        "        return \"*\"\n",
        "    return \"\"\n",
        "\n",
        "CLR_FLARE = \"#e41a1c\"\n",
        "CLR_REMIS = \"#f4a3b4\"\n",
        "\n",
        "# Titles and x-axis labels per metric\n",
        "metric_titles = {\n",
        "    \"REM_pct\": \"Rem\",\n",
        "    \"deep_pct\": \"Deep\",\n",
        "    \"light_pct\": \"Light\",\n",
        "    \"sleep_eff\": \"Sleep Efficiency\",\n",
        "    \"dur_asleep\": \"Time Asleep\",\n",
        "}\n",
        "\n",
        "xlabels = {\n",
        "    \"REM_pct\": \"% of Sleep (M ± SEM)\",\n",
        "    \"deep_pct\": \"% of Sleep (M ± SEM)\",\n",
        "    \"light_pct\": \"% of Sleep (M ± SEM)\",\n",
        "    \"sleep_eff\": \"Sleep Measure (M ± SEM)\",\n",
        "    \"dur_asleep\": \"Sleep Measure (M ± SEM)\",\n",
        "}\n",
        "\n",
        "# Ensure ordering of columns\n",
        "metric_order = [\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"]\n",
        "\n",
        "# ----------------------------\n",
        "# Prepare plotting data\n",
        "# ----------------------------\n",
        "# Split the table by predictor for quick lookup\n",
        "tbl = summary_df.copy()\n",
        "\n",
        "# Parse the \"False\" and \"True\" columns into mean & se\n",
        "parsed = []\n",
        "for _, row in tbl.iterrows():\n",
        "    m_false, se_false = parse_mean_se(row[\"False\"])\n",
        "    m_true,  se_true  = parse_mean_se(row[\"True\"])\n",
        "    parsed.append({\n",
        "        \"metric\": row[\"metric\"],\n",
        "        \"predictor\": row[\"predictor\"],\n",
        "        \"mean_false\": m_false,\n",
        "        \"se_false\": se_false,\n",
        "        \"mean_true\": m_true,\n",
        "        \"se_true\": se_true,\n",
        "        \"p_value\": float(row[\"p_value\"]),\n",
        "    })\n",
        "tbl_parsed = pd.DataFrame(parsed)\n",
        "\n",
        "# Convenience accessors for each predictor\n",
        "def row_for(metric, predictor):\n",
        "    return tbl_parsed[(tbl_parsed.metric == metric) & (tbl_parsed.predictor == predictor)].iloc[0]\n",
        "\n",
        "# ----------------------------\n",
        "# Plot\n",
        "# ----------------------------\n",
        "fig, axes = plt.subplots(2, 5, figsize=(16, 3.2), sharex='col', gridspec_kw=dict(wspace=0.1, hspace=0.35))\n",
        "\n",
        "row_info = [(\"flare\", \"IBD Inflammatory Flare\"), (\"symptom_flare\", \"IBD Symptom Flare\")]\n",
        "\n",
        "for col_idx, metric in enumerate(metric_order):\n",
        "    # Compute shared x-lims across both rows for this metric\n",
        "    mins, maxs = [], []\n",
        "    for predictor, _ylabel in row_info:\n",
        "        r = row_for(metric, predictor)\n",
        "        vals = [\n",
        "            r[\"mean_false\"] - r[\"se_false\"],\n",
        "            r[\"mean_true\"]  - r[\"se_true\"],\n",
        "            r[\"mean_false\"] + r[\"se_false\"],\n",
        "            r[\"mean_true\"]  + r[\"se_true\"],\n",
        "        ]\n",
        "        mins.append(np.nanmin(vals))\n",
        "        maxs.append(np.nanmax(vals))\n",
        "    xmin = np.nanmin(mins)\n",
        "    xmax = np.nanmax(maxs)\n",
        "    xrng = xmax - xmin\n",
        "    pad = 0.08 * xrng if xrng > 0 else 0.5\n",
        "    xmin -= pad\n",
        "    xmax += pad\n",
        "\n",
        "    for row_idx, (predictor, ylab) in enumerate(row_info):\n",
        "        ax = axes[row_idx, col_idx]\n",
        "        r = row_for(metric, predictor)\n",
        "\n",
        "        # Two slightly offset y positions so the two dots don't overlap\n",
        "        y_flare   = 0.58\n",
        "        y_remis   = 0.42\n",
        "\n",
        "        # Remission (False)\n",
        "        ax.errorbar(\n",
        "            r[\"mean_false\"], y_remis,\n",
        "            xerr=r[\"se_false\"],\n",
        "            fmt='o', ms=6, capsize=6, elinewidth=2, linewidth=2,\n",
        "            color=CLR_REMIS, mec=CLR_REMIS\n",
        "        )\n",
        "        # Flare (True)\n",
        "        ax.errorbar(\n",
        "            r[\"mean_true\"], y_flare,\n",
        "            xerr=r[\"se_true\"],\n",
        "            fmt='o', ms=6, capsize=6, elinewidth=2, linewidth=2,\n",
        "            color=CLR_FLARE, mec=CLR_FLARE\n",
        "        )\n",
        "\n",
        "        # Aesthetic tweaks\n",
        "        ax.set_ylim(0.2, 0.8)\n",
        "        ax.set_yticks([])  # hide per-panel y ticks; we add row labels on left only\n",
        "        ax.set_xlim(xmin, xmax)\n",
        "        ax.grid(axis='x', alpha=0.25)\n",
        "\n",
        "        # Add significance stars (top-right)\n",
        "        sig = stars_from_p(r[\"p_value\"])\n",
        "        if sig:\n",
        "            xmin, xmax = ax.get_xlim()\n",
        "            ymin, ymax = ax.get_ylim()\n",
        "\n",
        "            x_star = xmax - 0.05 * (xmax - xmin)\n",
        "            y_star = ymax - 0.10 * (ymax - ymin)\n",
        "\n",
        "            ax.text(x_star, y_star, sig, ha='right', va='top', fontsize=12, color='k')\n",
        "\n",
        "        # Titles on top row only\n",
        "        if row_idx == 0:\n",
        "            ax.set_title(metric_titles.get(metric, metric), fontsize=14, pad=6)\n",
        "\n",
        "        # Bottom row x-labels\n",
        "        if row_idx == 1:\n",
        "            ax.set_xlabel(xlabels[metric], fontsize=10)\n",
        "\n",
        "# Row labels on the left-most column\n",
        "axes[0, 0].set_ylabel(\"rate_as_flare\", fontsize=10, labelpad=10)\n",
        "axes[1, 0].set_ylabel(\"symptom_deg\", fontsize=10, labelpad=10)\n",
        "\n",
        "# Tight layout with a little extra left margin for row labels\n",
        "plt.subplots_adjust(left=0.10, right=0.98, top=0.88, bottom=0.20, wspace=0.35)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3nQ4ZuCyU5-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Physiological Metrics During Periods of Flares Compared with Periods of Remission (Restricted to User's that Contribute Both) - Welsh t-Test"
      ],
      "metadata": {
        "id": "AMeQuQjbs-Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "physiological_metrics = [\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"]\n",
        "groups = [\"CD\", \"UC\", \"IBD\"]\n",
        "flare_predictors = [\"symptom_flare\", \"flare\"]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# Compute differences & statistical tests\n",
        "for flare_col in flare_predictors:\n",
        "    results = []\n",
        "\n",
        "    for feature in physiological_metrics:\n",
        "        for diag in groups:\n",
        "            # Subset depending on group\n",
        "            if diag == \"IBD\":\n",
        "                relevant = merged[merged[\"diagnosis\"].isin([\"CD\", \"UC\"])]\n",
        "            else:\n",
        "                relevant = merged[merged[\"diagnosis\"] == diag]\n",
        "\n",
        "            #  Only keep users with both flare and remission data\n",
        "            users_with_both = relevant.groupby(\"user_id\")[flare_col].nunique()\n",
        "            users_with_both = users_with_both[users_with_both == 2].index\n",
        "\n",
        "            df_flare = relevant[(relevant[\"user_id\"].isin(users_with_both)) & (relevant[flare_col] == True)]\n",
        "            df_remission = relevant[(relevant[\"user_id\"].isin(users_with_both)) & (relevant[flare_col] == False)]\n",
        "\n",
        "            # Skip if no overlap\n",
        "            if df_flare.empty or df_remission.empty:\n",
        "                continue\n",
        "\n",
        "            # Summary stats\n",
        "            flare_mean, flare_std, flare_n = (df_flare[feature].mean(), df_flare[feature].std(), df_flare[feature].count())\n",
        "            rem_mean, rem_std, rem_n = (df_remission[feature].mean(), df_remission[feature].std(), df_remission[feature].count())\n",
        "\n",
        "            # Difference\n",
        "            diff = flare_mean - rem_mean\n",
        "\n",
        "            # Welch’s t-test\n",
        "            t_stat, p_val = stats.ttest_ind(df_flare[feature].dropna(), df_remission[feature].dropna(), equal_var=False)\n",
        "\n",
        "            # Confidence interval\n",
        "            cm = sm.stats.CompareMeans.from_data(df_flare[feature].dropna(), df_remission[feature].dropna())\n",
        "            ci_low, ci_high = cm.tconfint_diff(usevar='unequal')\n",
        "\n",
        "            results.append({\n",
        "                \"flare_col\": flare_col,\n",
        "                \"feature\": feature,\n",
        "                \"diagnosis\": diag,\n",
        "                \"flare_mean\": flare_mean,\n",
        "                \"flare_std\": flare_std,\n",
        "                \"flare_n\": flare_n,\n",
        "                \"rem_mean\": rem_mean,\n",
        "                \"rem_std\": rem_std,\n",
        "                \"rem_n\": rem_n,\n",
        "                \"diff\": diff,\n",
        "                \"ci_low\": ci_low,\n",
        "                \"ci_high\": ci_high,\n",
        "                \"p_value\": p_val\n",
        "            })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Significance stars\n",
        "    def significance_stars(p):\n",
        "        if p < 0.001:\n",
        "            return \"***\"\n",
        "        elif p < 0.01:\n",
        "            return \"**\"\n",
        "        elif p < 0.05:\n",
        "            return \"*\"\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "    results_df[\"stars\"] = results_df[\"p_value\"].apply(significance_stars)\n",
        "\n",
        "    all_results.append(results_df)\n",
        "\n",
        "# Combine results from both flare predictors\n",
        "final_results_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "# Display results\n",
        "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
        "display_df = final_results_df[[\"flare_col\", \"feature\", \"diagnosis\", \"flare_mean\", \"rem_mean\",  \"flare_std\", \"flare_n\", \"rem_n\", \"rem_std\", \"p_value\", \"stars\"]]\n",
        "\n",
        "display_df"
      ],
      "metadata": {
        "id": "g2F-Yh7KtB4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Physiological Metrics During Periods of Flares Compared with Periods of Remission (Restricted to User's that Contribute Both) - Paired t-Test"
      ],
      "metadata": {
        "id": "1qMBVGxxtuSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "physiological_metrics = [\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"]\n",
        "groups = [\"CD\", \"UC\", \"IBD\"]\n",
        "flare_predictors = [\"symptom_flare\", \"flare\"]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for flare_col in flare_predictors:\n",
        "    results = []\n",
        "\n",
        "    for feature in physiological_metrics:\n",
        "        for diag in groups:\n",
        "            # Subset relevant users depending on group\n",
        "            if diag == \"IBD\":\n",
        "                relevant = merged[merged[\"diagnosis\"].isin([\"CD\", \"UC\"])]\n",
        "            else:\n",
        "                relevant = merged[merged[\"diagnosis\"] == diag]\n",
        "\n",
        "            # If no rows at all for this group/feature, skip entirely\n",
        "            if relevant.empty:\n",
        "                continue\n",
        "\n",
        "            # Keep only users with at least one flare/remission record\n",
        "            # (we'll handle pairing below)\n",
        "            df_user = (\n",
        "                relevant.groupby([\"user_id\", flare_col])[feature]\n",
        "                .mean()\n",
        "                .unstack()\n",
        "            )\n",
        "\n",
        "            # Extract available states safely\n",
        "            flare_vals_all = df_user[True] if True in df_user.columns else pd.Series([], dtype=float)\n",
        "            rem_vals_all   = df_user[False] if False in df_user.columns else pd.Series([], dtype=float)\n",
        "\n",
        "            # Summary stats using all available values (even if unpaired)\n",
        "            flare_mean = flare_vals_all.mean() if not flare_vals_all.empty else np.nan\n",
        "            flare_std  = flare_vals_all.std(ddof=1) if len(flare_vals_all) > 1 else np.nan\n",
        "            flare_n    = int(flare_vals_all.count()) if not flare_vals_all.empty else 0\n",
        "\n",
        "            rem_mean   = rem_vals_all.mean() if not rem_vals_all.empty else np.nan\n",
        "            rem_std    = rem_vals_all.std(ddof=1) if len(rem_vals_all) > 1 else np.nan\n",
        "            rem_n      = int(rem_vals_all.count()) if not rem_vals_all.empty else 0\n",
        "\n",
        "            # Paired users = those with both states present (drop NaNs across both columns)\n",
        "            if {True, False}.issubset(df_user.columns):\n",
        "                df_pairs = df_user.dropna(subset=[True, False])\n",
        "            else:\n",
        "                df_pairs = pd.DataFrame(columns=[True, False])\n",
        "\n",
        "            paired_n = len(df_pairs)\n",
        "\n",
        "            # Differences & tests only from paired users\n",
        "            if paired_n >= 1:\n",
        "                diffs = df_pairs[True] - df_pairs[False]\n",
        "                diff = diffs.mean()\n",
        "            else:\n",
        "                diffs = pd.Series([], dtype=float)\n",
        "                diff = np.nan\n",
        "\n",
        "            # Paired t-test & 95% CI only if we have at least 2 pairs\n",
        "            if paired_n >= 2:\n",
        "                t_stat, p_val = stats.ttest_rel(df_pairs[True], df_pairs[False], nan_policy=\"omit\")\n",
        "\n",
        "                # CI (uses t distribution with df = n-1)\n",
        "                mean_diff = diffs.mean()\n",
        "                se_diff = diffs.std(ddof=1) / np.sqrt(paired_n)\n",
        "                t_crit = stats.t.ppf(0.975, paired_n - 1)\n",
        "                ci_low = mean_diff - t_crit * se_diff\n",
        "                ci_high = mean_diff + t_crit * se_diff\n",
        "            else:\n",
        "                p_val = np.nan\n",
        "                ci_low = np.nan\n",
        "                ci_high = np.nan\n",
        "\n",
        "            results.append({\n",
        "                \"flare_col\": flare_col,\n",
        "                \"feature\": feature,\n",
        "                \"diagnosis\": diag,\n",
        "                \"flare_mean\": flare_mean,\n",
        "                \"flare_std\": flare_std,\n",
        "                \"flare_n\": flare_n,\n",
        "                \"rem_mean\": rem_mean,\n",
        "                \"rem_std\": rem_std,\n",
        "                \"rem_n\": rem_n,\n",
        "                \"diff\": diff,\n",
        "                \"ci_low\": ci_low,\n",
        "                \"ci_high\": ci_high,\n",
        "                \"p_value\": p_val,\n",
        "                \"paired_n\": paired_n\n",
        "            })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Significance stars (handle NaN p-values)\n",
        "    def significance_stars(p):\n",
        "        if pd.isna(p):\n",
        "            return \"\"\n",
        "        if p < 0.001:\n",
        "            return \"***\"\n",
        "        elif p < 0.01:\n",
        "            return \"**\"\n",
        "        elif p < 0.05:\n",
        "            return \"*\"\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "    results_df[\"stars\"] = results_df[\"p_value\"].apply(significance_stars)\n",
        "    all_results.append(results_df)\n",
        "\n",
        "# Combine results from both flare predictors\n",
        "final_results_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "# Display results\n",
        "pd.set_option(\"display.float_format\", \"{:.3f}\".format)\n",
        "display_df = final_results_df[[\n",
        "    \"flare_col\", \"feature\", \"diagnosis\", \"paired_n\",\n",
        "    \"flare_mean\", \"rem_mean\",\n",
        "    \"flare_std\", \"rem_std\", \"p_value\", \"stars\"\n",
        "]]\n",
        "\n",
        "display_df"
      ],
      "metadata": {
        "id": "LpYwj52vtzxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Causal Inference Analysis"
      ],
      "metadata": {
        "id": "7IPN5Kax4WRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trajectories of Sleep Metrics Around Flares"
      ],
      "metadata": {
        "id": "ua8Mtqhh4e4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Aggregated"
      ],
      "metadata": {
        "id": "34gsD2OAzm8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics_around_flares(\n",
        "    flare_df,\n",
        "    objective,\n",
        "    metrics,\n",
        "    pre_days=45,\n",
        "    post_days=45,\n",
        "    ncols=5,\n",
        "    poly_degree=3,\n",
        "    min_days_threshold=7,\n",
        "    method=\"AND\",\n",
        "    raw_scatter_jitter=0.12,\n",
        "    raw_scatter_size=12,\n",
        "    raw_scatter_alpha=0.75,\n",
        "    rng_seed=42\n",
        "):\n",
        "\n",
        "    # ---------- Display names + font sizes ----------\n",
        "    metric_display = {\n",
        "        \"REM_pct\": \"REM Sleep (%)\",\n",
        "        \"deep_pct\": \"Deep Sleep (%)\",\n",
        "        \"light_pct\": \"Light Sleep (%)\",\n",
        "        \"sleep_eff\": \"Sleep Efficiency (%)\",\n",
        "        \"dur_asleep\": \"Total Time Asleep (h)\",\n",
        "    }\n",
        "    title_fontsize = 18\n",
        "    label_fontsize = 15\n",
        "    # ------------------------------------------------\n",
        "\n",
        "    # Copy + ensure datetime\n",
        "    flare = flare_df.copy()\n",
        "    obj_daily = objective.copy()\n",
        "    flare[\"date_flare_onset\"] = pd.to_datetime(flare[\"date_flare_onset\"])\n",
        "    flare[\"date_flare_end\"] = pd.to_datetime(flare[\"date_flare_end\"])\n",
        "    obj_daily[\"date\"] = pd.to_datetime(obj_daily[\"date\"])\n",
        "\n",
        "    # relative index for x-axis\n",
        "    rel_index = list(range(-pre_days, 0)) + [0] + list(range(1, post_days + 1))\n",
        "\n",
        "    # storage\n",
        "    metric_values = {m: defaultdict(list) for m in metrics}\n",
        "    contributing_flares = {m: set() for m in metrics}\n",
        "    flare_lengths = {m: [] for m in metrics}\n",
        "    datapoints_within_flare = {m: [] for m in metrics}\n",
        "    raw_points_pre = {m: 0 for m in metrics}\n",
        "    raw_points_post = {m: 0 for m in metrics}\n",
        "\n",
        "    # iterate over flares\n",
        "    for flare_idx, row in flare.iterrows():\n",
        "        uid, onset, end = row[\"user_id\"], row[\"date_flare_onset\"], row[\"date_flare_end\"]\n",
        "\n",
        "        # temp buffers for this flare (only merged if flare passes thresholds)\n",
        "        this_flare_values = {m: defaultdict(list) for m in metrics}\n",
        "        contributed_this_flare = {m: False for m in metrics}\n",
        "        points_within = {m: 0 for m in metrics}\n",
        "        pre_points_count, post_points_count = 0, 0\n",
        "\n",
        "        # --- compute subject's mean during flare for normalization ---\n",
        "        mask = (\n",
        "            (obj_daily[\"user_id\"] == uid)\n",
        "            & (obj_daily[\"date\"] >= onset)\n",
        "            & (obj_daily[\"date\"] <= end)\n",
        "        )\n",
        "        flare_vals = obj_daily.loc[mask, metrics]\n",
        "        flare_means = flare_vals.mean().to_dict()\n",
        "\n",
        "        # Rule 1: skip if 0 datapoints during flare\n",
        "        if flare_vals.empty:\n",
        "            continue\n",
        "\n",
        "        # pre days (buffer only)\n",
        "        for d in range(-pre_days, 0):\n",
        "            qdate = onset + pd.Timedelta(days=d)\n",
        "            vals = obj_daily[(obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] == qdate)]\n",
        "            if not vals.empty:\n",
        "                pre_points_count += 1\n",
        "                for m in metrics:\n",
        "                    v = vals[m].mean()\n",
        "                    if pd.notna(v) and pd.notna(flare_means[m]):\n",
        "                        v_norm = v - flare_means[m]\n",
        "                        this_flare_values[m][d].append(v_norm)\n",
        "                        contributed_this_flare[m] = True\n",
        "\n",
        "        # post days (buffer only)\n",
        "        for d in range(1, post_days + 1):\n",
        "            qdate = end + pd.Timedelta(days=d)\n",
        "            vals = obj_daily[(obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] == qdate)]\n",
        "            if not vals.empty:\n",
        "                post_points_count += 1\n",
        "                for m in metrics:\n",
        "                    v = vals[m].mean()\n",
        "                    if pd.notna(v) and pd.notna(flare_means[m]):\n",
        "                        v_norm = v - flare_means[m]\n",
        "                        this_flare_values[m][d].append(v_norm)\n",
        "                        contributed_this_flare[m] = True\n",
        "\n",
        "        # Rule 2: flexible datapoint threshold (decide BEFORE merging buffered data)\n",
        "        if method.upper() == \"AND\":\n",
        "            if (pre_points_count < min_days_threshold) or (post_points_count < min_days_threshold):\n",
        "                continue\n",
        "        elif method.upper() == \"OR\":\n",
        "            if (pre_points_count < min_days_threshold) and (post_points_count < min_days_threshold):\n",
        "                continue\n",
        "        else:\n",
        "            raise ValueError(\"method must be 'AND' or 'OR'\")\n",
        "\n",
        "        # Flare passed thresholds → merge buffered data and add day 0\n",
        "        # collapse flare to 0 (normalized to its own mean)\n",
        "        if mask.any():\n",
        "            for m in metrics:\n",
        "                v = flare_means[m]\n",
        "                if pd.notna(v):\n",
        "                    v_norm0 = 0.0\n",
        "                    metric_values[m][0].append(v_norm0)\n",
        "                    contributed_this_flare[m] = True\n",
        "                    points_within[m] = int(mask.sum())\n",
        "\n",
        "        # merge buffered pre/post values; update raw counters for INCLUDED flares only\n",
        "        for m in metrics:\n",
        "            # merge values\n",
        "            for d, lst in this_flare_values[m].items():\n",
        "                metric_values[m][d].extend(lst)\n",
        "\n",
        "            # update raw counts\n",
        "            pre_added = sum(len(this_flare_values[m][d]) for d in range(-pre_days, 0))\n",
        "            post_added = sum(len(this_flare_values[m][d]) for d in range(1, post_days + 1))\n",
        "            raw_points_pre[m] += pre_added\n",
        "            raw_points_post[m] += post_added\n",
        "\n",
        "        # update contributing sets and flare stats (included flares only)\n",
        "        flare_len = (end - onset).days + 1\n",
        "        for m in metrics:\n",
        "            if contributed_this_flare[m]:\n",
        "                contributing_flares[m].add(flare_idx)\n",
        "                flare_lengths[m].append(flare_len)\n",
        "                if points_within[m] > 0:\n",
        "                    datapoints_within_flare[m].append(points_within[m])\n",
        "\n",
        "    # setup subplot grid\n",
        "    nrows = int(np.ceil(len(metrics) / ncols))\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(6 * ncols, 4 * nrows), squeeze=False)\n",
        "\n",
        "    rng = np.random.default_rng(rng_seed)\n",
        "    results = {}\n",
        "\n",
        "    for i, m in enumerate(metrics):\n",
        "        ax = axes[i // ncols, i % ncols]\n",
        "\n",
        "        # aggregate per relative day (for mean curve + counts)\n",
        "        x_vals, means = [], []\n",
        "        for d in rel_index:\n",
        "            vals = metric_values[m].get(d, [])\n",
        "            if len(vals) > 0:\n",
        "                mean = np.mean(vals)\n",
        "            else:\n",
        "                mean = np.nan\n",
        "            x_vals.append(d)\n",
        "            means.append(mean)\n",
        "\n",
        "        x = np.array(x_vals)\n",
        "        y = np.array(means)\n",
        "\n",
        "        # ---------- RAW POINTS: scatter all contributing values ----------\n",
        "        # We add a tiny horizontal jitter so overlapping points are visible.\n",
        "        raw_x, raw_y = [], []\n",
        "        for d in rel_index:\n",
        "            vals = metric_values[m].get(d, [])\n",
        "            if len(vals) == 0:\n",
        "                continue\n",
        "            # jitter per point\n",
        "            jitter = rng.uniform(-raw_scatter_jitter, raw_scatter_jitter, size=len(vals))\n",
        "            raw_x.extend(d + jitter)\n",
        "            raw_y.extend(vals)\n",
        "        if len(raw_x) > 0:\n",
        "            ax.scatter(\n",
        "                raw_x,\n",
        "                raw_y,\n",
        "                s=raw_scatter_size,\n",
        "                c=\"lightgrey\",\n",
        "                alpha=raw_scatter_alpha,\n",
        "                edgecolors=\"none\"\n",
        "            )\n",
        "        # -----------------------------------------------------------------\n",
        "\n",
        "        # polynomial regression fit (to per-day means)\n",
        "        valid = ~np.isnan(y)\n",
        "        coeffs = np.polyfit(x[valid], y[valid], deg=poly_degree) if valid.sum() >= poly_degree + 1 else None\n",
        "\n",
        "        if coeffs is not None:\n",
        "            xsmooth = np.linspace(x.min(), x.max(), 400)\n",
        "            ysmooth = np.polyval(coeffs, xsmooth)\n",
        "            ax.plot(xsmooth, ysmooth, color=\"blue\", linewidth=2)\n",
        "\n",
        "        ax.axvline(0, linestyle=\"--\", color=\"red\", linewidth=0.8)\n",
        "\n",
        "        # ---------- Titles & Labels ----------\n",
        "        display_name = metric_display.get(m, m)\n",
        "        ax.set_title(display_name, fontsize=title_fontsize)\n",
        "        ax.set_xlabel(\"Days relative to flare (0 = flare mean)\", fontsize=label_fontsize)\n",
        "        ax.set_ylabel(\"Δ \" + display_name, fontsize=label_fontsize)\n",
        "        # ------------------------------------\n",
        "\n",
        "        ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
        "\n",
        "        # counts (raw, not collapsed) — INCLUDED flares only\n",
        "        pre_points = raw_points_pre[m]\n",
        "        flare_points = int(np.sum(datapoints_within_flare[m])) if datapoints_within_flare[m] else 0\n",
        "        post_points = raw_points_post[m]\n",
        "        total_points = pre_points + flare_points + post_points\n",
        "        num_flares = len(contributing_flares[m])\n",
        "\n",
        "        avg_len = np.mean(flare_lengths[m]) if flare_lengths[m] else np.nan\n",
        "        avg_points_within = np.mean(datapoints_within_flare[m]) if datapoints_within_flare[m] else np.nan\n",
        "\n",
        "        print(\n",
        "            f\"[{m}] {num_flares} contributing flares | \"\n",
        "            f\"avg length: {avg_len:.2f} days | \"\n",
        "            f\"avg datapoints within flare: {avg_points_within:.2f} | \"\n",
        "            f\"pre: {pre_points} pts, flare: {flare_points} pts, post: {post_points} pts \"\n",
        "            f\"(total={total_points})\"\n",
        "        )\n",
        "\n",
        "        results[m] = {\n",
        "            \"coeffs\": coeffs,\n",
        "            \"num_flares\": num_flares,\n",
        "            \"avg_flare_length\": avg_len,\n",
        "            \"avg_points_within_flare\": avg_points_within,\n",
        "            \"raw_counts\": {\"pre\": pre_points, \"flare\": flare_points, \"post\": post_points},\n",
        "        }\n",
        "\n",
        "    # hide unused axes\n",
        "    nrows = int(np.ceil(len(metrics) / ncols))\n",
        "    for j in range(len(metrics), nrows * ncols):\n",
        "        axes[j // ncols, j % ncols].axis(\"off\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "ng2-DVrBsL41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = plot_metrics_around_flares(summary_regular_flares, objective, metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"], min_days_threshold=10, method=\"AND\")"
      ],
      "metadata": {
        "id": "_38NCk-asxxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = plot_metrics_around_flares(summary_symptom_flares, objective, metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"], min_days_threshold=10, method=\"AND\")"
      ],
      "metadata": {
        "id": "3k4-hhnTtjZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Individual"
      ],
      "metadata": {
        "id": "2HZr4O5ZztKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_plottable_flares(\n",
        "    flare_df,\n",
        "    objective,\n",
        "    metrics,\n",
        "    pre_days=45,\n",
        "    post_days=45,\n",
        "    min_days_threshold=7,\n",
        "    method=\"OR\",\n",
        "):\n",
        "\n",
        "    # normalize inputs\n",
        "    if isinstance(metrics, str):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    flare = flare_df.copy()\n",
        "    obj = objective.copy()\n",
        "\n",
        "    flare[\"date_flare_onset\"] = pd.to_datetime(flare[\"date_flare_onset\"])\n",
        "    flare[\"date_flare_end\"] = pd.to_datetime(flare[\"date_flare_end\"])\n",
        "    obj[\"date\"] = pd.to_datetime(obj[\"date\"])\n",
        "\n",
        "    # Pre-aggregate daily means per metric to match plotting logic\n",
        "    obj_daily_all = {}\n",
        "    for metric in metrics:\n",
        "        obj_metric = obj.copy()\n",
        "        obj_metric[metric] = pd.to_numeric(obj_metric[metric], errors=\"coerce\")\n",
        "        obj_daily_all[metric] = (\n",
        "            obj_metric.groupby([\"user_id\", \"date\"], as_index=False)[metric].mean()\n",
        "        )\n",
        "\n",
        "    rel_index = list(range(-pre_days, 0)) + [0] + list(range(1, post_days + 1))\n",
        "    plottable_indices = []\n",
        "\n",
        "    # Check each flare once\n",
        "    for flare_idx, row in flare.iterrows():\n",
        "        uid, onset, end = row[\"user_id\"], row[\"date_flare_onset\"], row[\"date_flare_end\"]\n",
        "\n",
        "        # if ANY metric qualifies, we keep this flare\n",
        "        any_metric_ok = False\n",
        "\n",
        "        for metric in metrics:\n",
        "            obj_daily = obj_daily_all[metric]\n",
        "\n",
        "            # values during flare (for normalization)\n",
        "            mask = (obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] >= onset) & (obj_daily[\"date\"] <= end)\n",
        "            flare_vals = obj_daily.loc[mask, metric]\n",
        "\n",
        "            # Rule 1: must have some data during flare\n",
        "            if flare_vals.empty:\n",
        "                continue\n",
        "\n",
        "            flare_mean = flare_vals.mean()\n",
        "            if pd.isna(flare_mean):\n",
        "                continue\n",
        "\n",
        "            # Count pre/post days with any data\n",
        "            pre_points_count = sum(\n",
        "                not obj_daily[(obj_daily[\"user_id\"] == uid) &\n",
        "                              (obj_daily[\"date\"] == (onset + pd.Timedelta(days=d)))].empty\n",
        "                for d in range(-pre_days, 0)\n",
        "            )\n",
        "            post_points_count = sum(\n",
        "                not obj_daily[(obj_daily[\"user_id\"] == uid) &\n",
        "                              (obj_daily[\"date\"] == (end + pd.Timedelta(days=d)))].empty\n",
        "                for d in range(1, post_days + 1)\n",
        "            )\n",
        "\n",
        "            # Rule 2: threshold logic\n",
        "            if method.upper() == \"AND\":\n",
        "                if (pre_points_count < min_days_threshold) or (post_points_count < min_days_threshold):\n",
        "                    continue\n",
        "            elif method.upper() == \"OR\":\n",
        "                if (pre_points_count < min_days_threshold) and (post_points_count < min_days_threshold):\n",
        "                    continue\n",
        "            else:\n",
        "                raise ValueError(\"method must be 'AND' or 'OR'\")\n",
        "\n",
        "            # Build the highlighted trajectory (same as plotting) — we only need to know\n",
        "            # if there is at least one valid, normalized point to plot.\n",
        "            has_any_point = False\n",
        "            for d in rel_index:\n",
        "                if d < 0:\n",
        "                    qdate = onset + pd.Timedelta(days=d)\n",
        "                    vals = obj_daily[(obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] == qdate)][metric]\n",
        "                elif d == 0:\n",
        "                    vals = flare_vals\n",
        "                else:\n",
        "                    qdate = end + pd.Timedelta(days=d)\n",
        "                    vals = obj_daily[(obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] == qdate)][metric]\n",
        "\n",
        "                if not vals.empty:\n",
        "                    v = vals.mean()\n",
        "                    if pd.notna(v):\n",
        "                        has_any_point = True\n",
        "                        break\n",
        "\n",
        "            if has_any_point:\n",
        "                any_metric_ok = True\n",
        "                break\n",
        "\n",
        "        if any_metric_ok:\n",
        "            plottable_indices.append(flare_idx)\n",
        "\n",
        "    return plottable_indices\n",
        "\n",
        "\n",
        "def plot_metrics_with_spaghetti_highlight(\n",
        "    flare_df,\n",
        "    objective,\n",
        "    metrics,\n",
        "    pre_days=45,\n",
        "    post_days=45,\n",
        "    poly_degree=3,\n",
        "    highlight=None,\n",
        "    highlight_color=\"orange\",\n",
        "    sharey=False,\n",
        "    min_days_threshold=7,\n",
        "    method=\"OR\",\n",
        "    raw_scatter_jitter=0.12,\n",
        "    raw_scatter_size=12,\n",
        "    raw_scatter_alpha=0.75,\n",
        "    highlight_scatter_size=20,\n",
        "    rng_seed=42\n",
        "):\n",
        "\n",
        "    # ---------- Display names + font sizes ----------\n",
        "    metric_display = {\n",
        "        \"REM_pct\": \"REM Sleep (%)\",\n",
        "        \"deep_pct\": \"Deep Sleep (%)\",\n",
        "        \"light_pct\": \"Light Sleep (%)\",\n",
        "        \"sleep_eff\": \"Sleep Efficiency (%)\",\n",
        "        \"dur_asleep\": \"Total Time Asleep (h)\",\n",
        "    }\n",
        "    title_fontsize = 18\n",
        "    label_fontsize = 15\n",
        "    # ------------------------------------------------\n",
        "\n",
        "    # Ensure metrics is a list\n",
        "    if isinstance(metrics, str):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    flare = flare_df.copy()\n",
        "    obj = objective.copy()\n",
        "    flare[\"date_flare_onset\"] = pd.to_datetime(flare[\"date_flare_onset\"])\n",
        "    flare[\"date_flare_end\"] = pd.to_datetime(flare[\"date_flare_end\"])\n",
        "    obj[\"date\"] = pd.to_datetime(obj[\"date\"])\n",
        "\n",
        "    rel_index = list(range(-pre_days, 0)) + [0] + list(range(1, post_days + 1))\n",
        "    rng = np.random.default_rng(rng_seed)\n",
        "\n",
        "    # Build figure; if nothing to highlight, we'll close it.\n",
        "    fig, axes = plt.subplots(\n",
        "        1, len(metrics), figsize=(7 * len(metrics), 5), sharey=sharey\n",
        "    )\n",
        "    if len(metrics) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    has_highlight_any_metric = False\n",
        "\n",
        "    # Iterate over metrics\n",
        "    for m_idx, (ax, metric) in enumerate(zip(axes, metrics)):\n",
        "        # aggregate daily per user (keep metric numeric only)\n",
        "        obj[metric] = pd.to_numeric(obj[metric], errors=\"coerce\")\n",
        "        obj_daily = obj.groupby([\"user_id\", \"date\"], as_index=False)[metric].mean()\n",
        "\n",
        "        # store values per day for group aggregation\n",
        "        metric_values = {d: [] for d in rel_index}\n",
        "        # highlighted trajectory for this metric (only if same flare index)\n",
        "        highlight_traj = None  # tuple: (uid, flare_idx, days_np, values_np)\n",
        "\n",
        "        # iterate over flares\n",
        "        for flare_idx, row in flare.iterrows():\n",
        "            uid, onset, end = row[\"user_id\"], row[\"date_flare_onset\"], row[\"date_flare_end\"]\n",
        "\n",
        "            # --- compute subject's mean during flare for normalization ---\n",
        "            mask = (obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] >= onset) & (obj_daily[\"date\"] <= end)\n",
        "            flare_vals = obj_daily.loc[mask, metric]\n",
        "\n",
        "            # Rule 1: skip if 0 datapoints during flare\n",
        "            if flare_vals.empty:\n",
        "                continue\n",
        "\n",
        "            flare_mean = flare_vals.mean()\n",
        "            if pd.isna(flare_mean):\n",
        "                continue\n",
        "\n",
        "            # --- check pre and post datapoints ---\n",
        "            pre_points_count, post_points_count = 0, 0\n",
        "            for d in range(-pre_days, 0):\n",
        "                qdate = onset + pd.Timedelta(days=d)\n",
        "                if not obj_daily[(obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] == qdate)].empty:\n",
        "                    pre_points_count += 1\n",
        "            for d in range(1, post_days + 1):\n",
        "                qdate = end + pd.Timedelta(days=d)\n",
        "                if not obj_daily[(obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] == qdate)].empty:\n",
        "                    post_points_count += 1\n",
        "\n",
        "            # Rule 2: flexible datapoint threshold\n",
        "            if method.upper() == \"AND\":\n",
        "                if (pre_points_count < min_days_threshold) or (post_points_count < min_days_threshold):\n",
        "                    continue\n",
        "            elif method.upper() == \"OR\":\n",
        "                if (pre_points_count < min_days_threshold) and (post_points_count < min_days_threshold):\n",
        "                    continue\n",
        "            else:\n",
        "                raise ValueError(\"method must be 'AND' or 'OR'\")\n",
        "\n",
        "            # --- build trajectory (per-day normalized values for this flare) ---\n",
        "            traj, days = [], []\n",
        "            for d in rel_index:\n",
        "                if d < 0:\n",
        "                    qdate = onset + pd.Timedelta(days=d)\n",
        "                    vals = obj_daily[(obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] == qdate)][metric]\n",
        "                elif d == 0:\n",
        "                    vals = flare_vals\n",
        "                else:  # post days\n",
        "                    qdate = end + pd.Timedelta(days=d)\n",
        "                    vals = obj_daily[(obj_daily[\"user_id\"] == uid) & (obj_daily[\"date\"] == qdate)][metric]\n",
        "\n",
        "                if not vals.empty:\n",
        "                    v = vals.mean()\n",
        "                    if pd.notna(v):\n",
        "                        v_norm = v - flare_mean\n",
        "                        traj.append(v_norm)\n",
        "                        metric_values[d].append(v_norm)\n",
        "                    else:\n",
        "                        traj.append(np.nan)\n",
        "                else:\n",
        "                    traj.append(np.nan)\n",
        "                days.append(d)\n",
        "\n",
        "            # If this is the selected flare, keep its trajectory for *this* metric\n",
        "            if highlight is not None and flare_idx == highlight:\n",
        "                if np.any(pd.notna(traj)):\n",
        "                    highlight_traj = (uid, flare_idx, np.array(days, dtype=float), np.array(traj, dtype=float))\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 1) RAW POINTS: Plot ALL contributing datapoints as light grey dots\n",
        "        # ------------------------------------------------------------------\n",
        "        raw_x, raw_y = [], []\n",
        "        for d in rel_index:\n",
        "            vals = metric_values[d]\n",
        "            if len(vals) == 0:\n",
        "                continue\n",
        "            jitter = rng.uniform(-raw_scatter_jitter, raw_scatter_jitter, size=len(vals))\n",
        "            raw_x.extend(d + jitter)\n",
        "            raw_y.extend(vals)\n",
        "        if len(raw_x) > 0:\n",
        "            ax.scatter(\n",
        "                raw_x, raw_y,\n",
        "                s=raw_scatter_size,\n",
        "                c=\"lightgrey\",\n",
        "                alpha=raw_scatter_alpha,\n",
        "                edgecolors=\"none\",\n",
        "                label=\"Raw datapoints\"\n",
        "            )\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 2) GROUP MEAN POLYNOMIAL (blue) — fit to per-day means (with intercept)\n",
        "        # ------------------------------------------------------------------\n",
        "        x_vals, means = [], []\n",
        "        for d in rel_index:\n",
        "            vals = metric_values[d]\n",
        "            mean = np.mean(vals) if len(vals) > 0 else np.nan\n",
        "            x_vals.append(d)\n",
        "            means.append(mean)\n",
        "\n",
        "        x = np.array(x_vals, dtype=float)\n",
        "        y = np.array(means, dtype=float)\n",
        "        valid = ~np.isnan(y)\n",
        "\n",
        "        if valid.sum() >= poly_degree + 1:\n",
        "            coeffs = np.polyfit(x[valid], y[valid], deg=poly_degree)\n",
        "            xsmooth = np.linspace(x.min(), x.max(), 400)\n",
        "            ysmooth = np.polyval(coeffs, xsmooth)\n",
        "            ax.plot(xsmooth, ysmooth, color=\"blue\", linewidth=2, label=f\"Group poly{poly_degree}\")\n",
        "\n",
        "        # ------------------------------------------------------------------\n",
        "        # 3) HIGHLIGHTED TRAJECTORY: orange points + ORIGIN-ANCHORED polynomial\n",
        "        # ------------------------------------------------------------------\n",
        "        if highlight_traj is not None:\n",
        "            uid, fidx, days, values = highlight_traj\n",
        "            hv_valid = ~np.isnan(values)\n",
        "\n",
        "            if hv_valid.any():\n",
        "                has_highlight_any_metric = True\n",
        "\n",
        "                # orange scatter points (jittered)\n",
        "                hjitter = rng.uniform(-raw_scatter_jitter, raw_scatter_jitter, size=hv_valid.sum())\n",
        "                uid_short = str(uid)[:7] + \"...\"\n",
        "                ax.scatter(\n",
        "                    days[hv_valid] + hjitter,\n",
        "                    values[hv_valid],\n",
        "                    s=highlight_scatter_size,\n",
        "                    c=highlight_color,\n",
        "                    alpha=0.95,\n",
        "                    label=f\"Highlight points (uid={uid_short}, flare={fidx})\"\n",
        "                )\n",
        "\n",
        "                # Fit polynomial THROUGH ORIGIN (0,0)\n",
        "                xh = days[hv_valid].astype(float)\n",
        "                yh = values[hv_valid].astype(float)\n",
        "                # Require at least one nonzero x to avoid singularity\n",
        "                nonzero = xh != 0\n",
        "                if nonzero.any():\n",
        "                    deg_anchor = max(1, min(poly_degree, nonzero.sum()))\n",
        "                    X = np.column_stack([xh[nonzero]**k for k in range(1, deg_anchor + 1)])\n",
        "                    try:\n",
        "                        coefs, *_ = np.linalg.lstsq(X, yh[nonzero], rcond=None)\n",
        "                        xs = np.linspace(xh.min(), xh.max(), 300)\n",
        "                        Xs = np.column_stack([xs**k for k in range(1, deg_anchor + 1)])\n",
        "                        ys = Xs @ coefs\n",
        "                        ax.plot(xs, ys, color=highlight_color, linewidth=2.5,\n",
        "                                label=f\"Highlight poly{deg_anchor} (uid={uid_short})\")\n",
        "                    except np.linalg.LinAlgError:\n",
        "                        pass\n",
        "\n",
        "        # cosmetics\n",
        "        ax.axvline(0, linestyle=\"--\", color=\"red\", linewidth=0.8)\n",
        "        display_name = metric_display.get(metric, metric)\n",
        "        ax.set_title(display_name, fontsize=title_fontsize)\n",
        "        ax.set_xlabel(\"Days relative to flare (0 = flare mean)\", fontsize=label_fontsize)\n",
        "        ax.set_ylabel(\"Δ \" + display_name, fontsize=label_fontsize)\n",
        "        ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
        "\n",
        "        # only put legend on the first axis\n",
        "        if m_idx == 0:\n",
        "            ax.legend()\n",
        "\n",
        "    # If no metric had a valid highlighted trajectory, close and skip\n",
        "    if (highlight is not None) and (not has_highlight_any_metric):\n",
        "        plt.close(fig)\n",
        "        return False\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return True"
      ],
      "metadata": {
        "id": "Cp8QT6ovHCT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plottable = list_plottable_flares(summary_symptom_flares, objective, metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"], pre_days=45, post_days=45, min_days_threshold=10, method=\"AND\")\n",
        "for idx in plottable:\n",
        "     plot_metrics_with_spaghetti_highlight(summary_symptom_flares, objective, metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"], pre_days=45, post_days=45, min_days_threshold=10, method=\"AND\", highlight=idx)"
      ],
      "metadata": {
        "id": "RFuqGZE6zvKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plottable = list_plottable_flares(summary_regular_flares, objective, metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"], pre_days=45, post_days=45, min_days_threshold=10, method=\"AND\")\n",
        "for idx in plottable:\n",
        "     plot_metrics_with_spaghetti_highlight(summary_regular_flares, objective, metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"], pre_days=45, post_days=45, min_days_threshold=10, method=\"AND\", highlight=idx)"
      ],
      "metadata": {
        "id": "ohRGf3wmG14r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rate of Change in Sleep Metrics Preceding and Following Flares"
      ],
      "metadata": {
        "id": "2uyNmp7Y71Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CONFIG\n",
        "# ==========================================================\n",
        "METRICS = [\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"]\n",
        "PRE_DAYS  = 45\n",
        "POST_DAYS = 45\n",
        "\n",
        "# ==========================================================\n",
        "# HELPERS\n",
        "# ==========================================================\n",
        "def _sig_marker(p):\n",
        "    if not np.isfinite(p): return \"ns\"\n",
        "    if p < 0.01: return \"**\"\n",
        "    if p < 0.05: return \"*\"\n",
        "    if p < 0.10: return \"+\"\n",
        "    return \"ns\"\n",
        "\n",
        "def _sem(x):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    if x.size <= 1:\n",
        "        return np.nan\n",
        "    return stats.sem(x)\n",
        "\n",
        "def _fit_slope_through_origin(days, values):\n",
        "    days = np.asarray(days, dtype=float)\n",
        "    values = np.asarray(values, dtype=float)\n",
        "    msk = ~np.isnan(days) & ~np.isnan(values)\n",
        "    days, values = days[msk], values[msk]\n",
        "    if days.size < 2:\n",
        "        return np.nan\n",
        "    return np.sum(days * values) / np.sum(days**2)\n",
        "\n",
        "def _fmt_slope(m, se):\n",
        "    if not np.isfinite(m) or not np.isfinite(se):\n",
        "        return \"–\"\n",
        "    return f\"{m:.3f} (SEM: {se:.3f})\"\n",
        "\n",
        "def _fmt_p(p):\n",
        "    if not np.isfinite(p):\n",
        "        return \"–\"\n",
        "    if p < 0.001:\n",
        "        return \"< .001\"\n",
        "    s = f\"{p:.2f}\"\n",
        "    if s.startswith(\"0\"):\n",
        "        s = s[1:]\n",
        "    return f\"= {s}\"\n",
        "\n",
        "def _span_correction(days_array, ref_span_days):\n",
        "    d = np.asarray(days_array, dtype=float)\n",
        "    if d.size == 0 or not np.isfinite(d).any():\n",
        "        return 1.0\n",
        "    span = np.nanmax(d) - np.nanmin(d)\n",
        "    if not np.isfinite(span) or span <= 0:\n",
        "        return 1.0\n",
        "    if not np.isfinite(ref_span_days) or ref_span_days <= 0:\n",
        "        return 1.0\n",
        "    return float(span) / float(ref_span_days)\n",
        "\n",
        "def compute_prepost_slopes_raw(flare_df, objective,\n",
        "                               metrics=METRICS,\n",
        "                               pre_days=PRE_DAYS,\n",
        "                               post_days=POST_DAYS,\n",
        "                               min_days_threshold=7,\n",
        "                               method=\"OR\"):\n",
        "    df = objective.copy()\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    fl = flare_df.copy()\n",
        "    fl[\"date_flare_onset\"] = pd.to_datetime(fl[\"date_flare_onset\"])\n",
        "    fl[\"date_flare_end\"]   = pd.to_datetime(fl[\"date_flare_end\"])\n",
        "\n",
        "    out_rows = []\n",
        "\n",
        "    for flare_id, row in fl.reset_index(drop=True).iterrows():\n",
        "        uid   = row[\"user_id\"]\n",
        "        start = row[\"date_flare_onset\"]\n",
        "        end   = row[\"date_flare_end\"]\n",
        "\n",
        "        u = df[df[\"user_id\"] == uid].copy()\n",
        "        if u.empty:\n",
        "            continue\n",
        "\n",
        "        # windows\n",
        "        pre   = u[(u[\"date\"] >= start - pd.Timedelta(days=pre_days)) & (u[\"date\"] <  start)]\n",
        "        post  = u[(u[\"date\"] >  end) & (u[\"date\"] <= end + pd.Timedelta(days=post_days))]\n",
        "        flare = u[(u[\"date\"] >= start) & (u[\"date\"] <= end)]\n",
        "\n",
        "        # Rule 1: skip if 0 datapoints during flare\n",
        "        if flare.empty:\n",
        "            continue\n",
        "\n",
        "        # Rule 2: flexible datapoint threshold requirement (applies to pre/post only)\n",
        "        n_pre, n_post = len(pre), len(post)\n",
        "        if method.upper() == \"AND\":\n",
        "            if (n_pre < min_days_threshold) or (n_post < min_days_threshold):\n",
        "                continue\n",
        "        elif method.upper() == \"OR\":\n",
        "            if (n_pre < min_days_threshold) and (n_post < min_days_threshold):\n",
        "                continue\n",
        "        else:\n",
        "            raise ValueError(\"method must be 'AND' or 'OR'\")\n",
        "\n",
        "        # normalization base (per flare, per metric): mean during the flare\n",
        "        flare_means = flare[metrics].mean()\n",
        "\n",
        "        for metric in metrics:\n",
        "            base = flare_means.get(metric, np.nan)\n",
        "            if not np.isfinite(base):\n",
        "                continue\n",
        "\n",
        "            # PRE slope (days negative; approach to flare start) + span normalization\n",
        "            if len(pre) >= min_days_threshold:\n",
        "                d = (pre[\"date\"] - start).dt.days.values\n",
        "                y = pre[metric].values.astype(float) - base\n",
        "                slope_day = _fit_slope_through_origin(d, y)\n",
        "                slope_day *= _span_correction(d, pre_days)\n",
        "                out_rows.append(dict(flare_id=flare_id, user_id=uid, phase=\"pre\",\n",
        "                                     metric=metric, slope_per_week=slope_day * 7.0))\n",
        "\n",
        "            # FLARE slope (within-flare, anchored at flare start) — no span normalization\n",
        "            if len(flare) >= 2:\n",
        "                d = (flare[\"date\"] - start).dt.days.values\n",
        "                y = flare[metric].values.astype(float) - base\n",
        "                slope_day = _fit_slope_through_origin(d, y)\n",
        "                out_rows.append(dict(flare_id=flare_id, user_id=uid, phase=\"flare\",\n",
        "                                     metric=metric, slope_per_week=slope_day * 7.0))\n",
        "\n",
        "            # POST slope (after flare end) + span normalization\n",
        "            if len(post) >= min_days_threshold:\n",
        "                d = (post[\"date\"] - end).dt.days.values\n",
        "                y = post[metric].values.astype(float) - base\n",
        "                slope_day = _fit_slope_through_origin(d, y)\n",
        "                slope_day *= _span_correction(d, post_days)\n",
        "                out_rows.append(dict(flare_id=flare_id, user_id=uid, phase=\"post\",\n",
        "                                     metric=metric, slope_per_week=slope_day * 7.0))\n",
        "\n",
        "    slopes = pd.DataFrame(out_rows)\n",
        "    return slopes\n",
        "\n",
        "def summarize_and_test_all(slopes, metrics=METRICS):\n",
        "\n",
        "    # summary by phase\n",
        "    summary = (slopes\n",
        "               .groupby([\"metric\", \"phase\"])[\"slope_per_week\"]\n",
        "               .agg(M=\"mean\", SEM=_sem, N=\"count\")\n",
        "               .reset_index())\n",
        "\n",
        "    # paired tests (+ paired N)\n",
        "    tests = []\n",
        "    for metric in metrics:\n",
        "        wide = (slopes[slopes[\"metric\"] == metric]\n",
        "                .pivot_table(index=[\"flare_id\", \"user_id\"],\n",
        "                             columns=\"phase\",\n",
        "                             values=\"slope_per_week\"))\n",
        "\n",
        "        def _paired_p_and_n(col_a, col_b):\n",
        "            if (col_a in wide.columns) and (col_b in wide.columns):\n",
        "                paired = wide.dropna(subset=[col_a, col_b])\n",
        "                n = int(paired.shape[0])\n",
        "                if n >= 2:\n",
        "                    _, p = stats.ttest_rel(paired[col_a], paired[col_b])\n",
        "                    return float(p), n\n",
        "                else:\n",
        "                    return np.nan, n\n",
        "            return np.nan, 0\n",
        "\n",
        "        p_pp, n_pp   = _paired_p_and_n(\"pre\", \"post\")\n",
        "        p_pf, n_pf   = _paired_p_and_n(\"pre\", \"flare\")\n",
        "        p_fp, n_fp   = _paired_p_and_n(\"flare\", \"post\")\n",
        "\n",
        "        tests.append(dict(metric=metric,\n",
        "                          comparison=\"Preflare vs. Postflare\",\n",
        "                          p=p_pp, N=n_pp))\n",
        "        tests.append(dict(metric=metric,\n",
        "                          comparison=\"Preflare vs. Flare\",\n",
        "                          p=p_pf, N=n_pf))\n",
        "        tests.append(dict(metric=metric,\n",
        "                          comparison=\"Flare vs. Postflare\",\n",
        "                          p=p_fp, N=n_fp))\n",
        "\n",
        "    tests_all = pd.DataFrame(tests)\n",
        "    return summary, tests_all\n",
        "\n",
        "def build_prepost_table(label, summary, tests_all, metrics=METRICS, metric_name_map=None):\n",
        "\n",
        "    rows = []\n",
        "    metric_name_map = metric_name_map or {}\n",
        "\n",
        "    # helper to fetch slope/sem for a (metric, phase)\n",
        "    def _get(summary, m, ph):\n",
        "        sm = summary[(summary[\"metric\"] == m) & (summary[\"phase\"] == ph)]\n",
        "        if sm.empty:\n",
        "            return np.nan, np.nan\n",
        "        return float(sm[\"M\"]), float(sm[\"SEM\"])\n",
        "\n",
        "    for m in metrics:\n",
        "        m_pre,  se_pre  = _get(summary, m, \"pre\")\n",
        "        m_flr,  se_flr  = _get(summary, m, \"flare\")\n",
        "        m_post, se_post = _get(summary, m, \"post\")\n",
        "\n",
        "        for comp in [\"Preflare vs. Postflare\", \"Preflare vs. Flare\", \"Flare vs. Postflare\"]:\n",
        "            p_row = tests_all[(tests_all[\"metric\"] == m) & (tests_all[\"comparison\"] == comp)]\n",
        "            p = float(p_row[\"p\"]) if not p_row.empty else np.nan\n",
        "            n = int(p_row[\"N\"]) if (not p_row.empty and np.isfinite(p_row[\"N\"]).all()) else 0\n",
        "\n",
        "            rows.append(dict(\n",
        "                Section=label,\n",
        "                Measurement=metric_name_map.get(m, m).replace(\"_\", \" \").title(),\n",
        "                **{\n",
        "                    \"n (flares)\": f\"n = {n}\" if n > 0 else \"n = 0\",\n",
        "                    \"Preflare Slope\":  _fmt_slope(m_pre,  se_pre),\n",
        "                    \"Flare Slope\":     _fmt_slope(m_flr,  se_flr),\n",
        "                    \"Postflare Slope\": _fmt_slope(m_post, se_post),\n",
        "                    \"Comparison\": comp,\n",
        "                    \"P-value\": _fmt_p(p)\n",
        "                }\n",
        "            ))\n",
        "\n",
        "    return pd.DataFrame(rows, columns=[\n",
        "        \"Section\", \"Measurement\", \"n (flares)\", \"Preflare Slope\", \"Flare Slope\",\n",
        "        \"Postflare Slope\", \"Comparison\", \"P-value\"\n",
        "    ])\n",
        "\n",
        "def plot_change_per_week_shared(groups, metrics=METRICS, metric_name_map=None,\n",
        "                                p_light=0.10, alpha_sig=1.0, alpha_ns=0.35):\n",
        "\n",
        "    metric_name_map = metric_name_map or {\n",
        "        \"REM_pct\": \"REM Sleep (%)\",\n",
        "        \"deep_pct\": \"Deep Sleep (%)\",\n",
        "        \"light_pct\": \"Light Sleep (%)\",\n",
        "        \"sleep_eff\": \"Sleep Efficiency (%)\",\n",
        "        \"dur_asleep\": \"Total Time Asleep (h)\",\n",
        "    }\n",
        "\n",
        "    colors = dict(pre=\"#6A1B9A\", post=\"#FF00B3\")\n",
        "    label_map = {\"pre\": \"Before Flare\", \"post\": \"After Flare\"}\n",
        "\n",
        "    G = len(groups)\n",
        "    M = len(metrics)\n",
        "    if G == 0 or M == 0:\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(G, M, figsize=(3*M, 1.7*G), squeeze=False)\n",
        "\n",
        "    # ---- compute shared x-lims per metric across all groups (PRE/POST ONLY)\n",
        "    shared_xlim = {}\n",
        "    for metric in metrics:\n",
        "        max_extent = []\n",
        "        for label, summary, tests in groups:\n",
        "            sm = summary[(summary[\"metric\"] == metric) &\n",
        "                         (summary[\"phase\"].isin([\"pre\", \"post\"]))]\n",
        "            if sm.empty:\n",
        "                continue\n",
        "            # extent = max(|mean| + SEM) over the plotted phases\n",
        "            Mvals = np.abs(sm[\"M\"].to_numpy())\n",
        "            SEvals = sm[\"SEM\"].fillna(0).to_numpy()\n",
        "            ext = np.nanmax(Mvals + SEvals) if Mvals.size else np.nan\n",
        "            if np.isfinite(ext):\n",
        "                max_extent.append(ext)\n",
        "\n",
        "        xmax = np.nanmax(max_extent) if max_extent else 1.0\n",
        "        if not np.isfinite(xmax) or xmax == 0:\n",
        "            xmax = 1.0\n",
        "        shared_xlim[metric] = (-1.2 * xmax, 1.2 * xmax)  # small padding\n",
        "\n",
        "    def _get_p_pre_post(tests_df, metric):\n",
        "        row = tests_df[(tests_df[\"metric\"] == metric) &\n",
        "                       (tests_df[\"comparison\"] == \"Preflare vs. Postflare\")]\n",
        "        return float(row[\"p\"]) if not row.empty else np.nan\n",
        "\n",
        "    for i, (label, summary, tests) in enumerate(groups):\n",
        "        for j, metric in enumerate(metrics):\n",
        "            ax = axes[i, j]\n",
        "            sm = summary[summary[\"metric\"] == metric]\n",
        "            if sm.empty:\n",
        "                ax.set_axis_off()\n",
        "                continue\n",
        "\n",
        "            p = _get_p_pre_post(tests, metric)\n",
        "            is_sig = np.isfinite(p) and (p < p_light)\n",
        "            alpha = alpha_sig if is_sig else alpha_ns\n",
        "\n",
        "            # plot pre/post only\n",
        "            for idx, phase in enumerate([\"pre\", \"post\"]):\n",
        "                row = sm[sm[\"phase\"] == phase]\n",
        "                if row.empty:\n",
        "                    continue\n",
        "                m  = float(row[\"M\"])\n",
        "                se = float(row[\"SEM\"]) if np.isfinite(row[\"SEM\"]).all() else np.nan\n",
        "                y = idx\n",
        "                ax.errorbar(m, y, xerr=se, fmt='o', capsize=4,\n",
        "                            color=colors[phase], alpha=alpha, markersize=8, lw=2,\n",
        "                            label=label_map[phase] if (i == 0 and j == 0) else None)\n",
        "\n",
        "            # significance marker positioned using pre/post only\n",
        "            sm_pp = sm[sm[\"phase\"].isin([\"pre\", \"post\"])]\n",
        "            if np.isfinite(p):\n",
        "                sig = _sig_marker(p)\n",
        "                if sig != \"ns\" and not sm_pp.empty:\n",
        "                    right_x = np.nanmax(sm_pp[\"M\"].to_numpy() +\n",
        "                                        sm_pp[\"SEM\"].fillna(0).to_numpy())\n",
        "                    ax.text(right_x + 0.08, 0.5, sig, va=\"center\", ha=\"left\", fontsize=11)\n",
        "\n",
        "            ax.axvline(0, color=\"k\", lw=2)\n",
        "            ax.set_yticks([0, 1]); ax.set_yticklabels([])\n",
        "            ax.set_ylim(-1, 2)\n",
        "            ax.set_xlim(shared_xlim[metric])\n",
        "            if i == 0:\n",
        "                ax.set_title(metric_name_map.get(metric, metric.replace(\"_\", \" \")))\n",
        "            if j == 0:\n",
        "                ax.set_ylabel(label)\n",
        "            ax.grid(True, axis=\"x\", linestyle=\":\", alpha=0.6)\n",
        "\n",
        "    handles, labels = axes[0,0].get_legend_handles_labels()\n",
        "    if handles:\n",
        "        fig.legend(handles, labels, loc=\"lower left\", ncol=2, frameon=False)\n",
        "    fig.text(0.5, 0.02, \"Change per week (M ± SEM)\", ha=\"center\", va=\"center\")\n",
        "    plt.tight_layout(rect=[0, 0.08, 1, 1])\n",
        "    plt.show()\n",
        "\n",
        "# USAGE\n",
        "# 1) summary_regular_flares\n",
        "slopes_infl = compute_prepost_slopes_raw(summary_regular_flares, objective, metrics=METRICS, min_days_threshold=10, method=\"AND\")\n",
        "summary_infl, tests_infl_all = summarize_and_test_all(slopes_infl, metrics=METRICS)\n",
        "table_infl = build_prepost_table(\"Inflammatory Flares\", summary_infl, tests_infl_all, metrics=METRICS)\n",
        "\n",
        "# 2) summary_symptom_flares\n",
        "slopes_symp = compute_prepost_slopes_raw(summary_symptom_flares, objective, metrics=METRICS, min_days_threshold=10, method=\"AND\")\n",
        "summary_symp, tests_symp_all = summarize_and_test_all(slopes_symp, metrics=METRICS)\n",
        "table_symp = build_prepost_table(\"Symptomatic Flares\", summary_symp, tests_symp_all, metrics=METRICS)\n",
        "\n",
        "# 3) Combined pretty table\n",
        "final_table = pd.concat([table_infl, table_symp], ignore_index=True)\n",
        "\n",
        "final_table"
      ],
      "metadata": {
        "id": "n4WkWgxNqFKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_change_per_week_shared([(\"symptom_deg\",  summary_symp, tests_symp_all), (\"rate_as_flare\", summary_infl, tests_infl_all)], metrics=METRICS, p_light=0.10)"
      ],
      "metadata": {
        "id": "xFrzjK8AlJpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Aggregated Slopes"
      ],
      "metadata": {
        "id": "r1Zif0HOBIqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper: slope through origin\n",
        "def _fit_slope_through_origin(days, values):\n",
        "    days = np.asarray(days, dtype=float)\n",
        "    values = np.asarray(values, dtype=float)\n",
        "    msk = ~np.isnan(days) & ~np.isnan(values)\n",
        "    days, values = days[msk], values[msk]\n",
        "    if days.size < 2:\n",
        "        return np.nan\n",
        "    return np.sum(days * values) / np.sum(days**2)\n",
        "\n",
        "# display mapping and font sizes (adapted)\n",
        "metric_display = {\n",
        "    \"REM_pct\": \"REM Sleep (%)\",\n",
        "    \"deep_pct\": \"Deep Sleep (%)\",\n",
        "    \"light_pct\": \"Light Sleep (%)\",\n",
        "    \"sleep_eff\": \"Sleep Efficiency (%)\",\n",
        "    \"dur_asleep\": \"Total Time Asleep (h)\",\n",
        "}\n",
        "title_fontsize = 14\n",
        "label_fontsize = 12\n",
        "\n",
        "def plot_overlay_all_metrics(\n",
        "    flare_df,\n",
        "    objective,\n",
        "    metrics,\n",
        "    pre_days=45,\n",
        "    post_days=45,\n",
        "    alpha=0.15,\n",
        "    point_size=10,\n",
        "    min_days_threshold=10,\n",
        "    method=\"OR\",\n",
        "):\n",
        "    df = objective.copy()\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    fl = flare_df.copy()\n",
        "    fl[\"date_flare_onset\"] = pd.to_datetime(fl[\"date_flare_onset\"])\n",
        "    fl[\"date_flare_end\"]   = pd.to_datetime(fl[\"date_flare_end\"])\n",
        "\n",
        "    n = len(metrics)\n",
        "    fig, axes = plt.subplots(1, n, figsize=(4*n, 3), sharey=False)\n",
        "\n",
        "    if n == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, metric in zip(axes, metrics):\n",
        "        all_pre_days, all_pre_vals = [], []\n",
        "        all_post_days, all_post_vals = [], []\n",
        "\n",
        "        for _, row in fl.iterrows():\n",
        "            uid   = row[\"user_id\"]\n",
        "            start = row[\"date_flare_onset\"]\n",
        "            end   = row[\"date_flare_end\"]\n",
        "\n",
        "            u = df[df[\"user_id\"] == uid].copy()\n",
        "            if u.empty:\n",
        "                continue\n",
        "\n",
        "            pre  = u[(u[\"date\"] >= start - pd.Timedelta(days=pre_days)) & (u[\"date\"] <  start)]\n",
        "            post = u[(u[\"date\"] >  end) & (u[\"date\"] <= end + pd.Timedelta(days=post_days))]\n",
        "            flare= u[(u[\"date\"] >= start) & (u[\"date\"] <= end)]\n",
        "\n",
        "            if flare.empty:\n",
        "                continue\n",
        "\n",
        "            # --- FLEXIBLE SKIPPING LOGIC ---\n",
        "            n_pre, n_post = len(pre), len(post)\n",
        "            if method.upper() == \"AND\":\n",
        "                # require BOTH sides to meet threshold\n",
        "                if (n_pre < min_days_threshold) or (n_post < min_days_threshold):\n",
        "                    continue\n",
        "            elif method.upper() == \"OR\":\n",
        "                # require AT LEAST ONE side to meet threshold\n",
        "                if (n_pre < min_days_threshold) and (n_post < min_days_threshold):\n",
        "                    continue\n",
        "            else:\n",
        "                raise ValueError(\"method must be 'AND' or 'OR'\")\n",
        "            # --------------------------------\n",
        "\n",
        "            base = flare[metric].mean()\n",
        "            if not np.isfinite(base):\n",
        "                continue\n",
        "\n",
        "            if not pre.empty:\n",
        "                d = (pre[\"date\"] - start).dt.days.values\n",
        "                y = pre[metric].values.astype(float) - base\n",
        "                all_pre_days.extend(d)\n",
        "                all_pre_vals.extend(y)\n",
        "\n",
        "            if not post.empty:\n",
        "                d = (post[\"date\"] - end).dt.days.values\n",
        "                y = post[metric].values.astype(float) - base\n",
        "                all_post_days.extend(d)\n",
        "                all_post_vals.extend(y)\n",
        "\n",
        "        all_pre_days, all_pre_vals = np.array(all_pre_days), np.array(all_pre_vals)\n",
        "        all_post_days, all_post_vals = np.array(all_post_days), np.array(all_post_vals)\n",
        "\n",
        "        # scatter raw points\n",
        "        ax.scatter(\n",
        "            all_pre_days, all_pre_vals, color=\"#6A1B9A\", alpha=alpha, s=point_size,\n",
        "            label=\"Pre (raw)\" if metric == metrics[0] else \"\"\n",
        "        )\n",
        "        ax.scatter(\n",
        "            all_post_days, all_post_vals, color=\"#FF00B3\", alpha=alpha, s=point_size,\n",
        "            label=\"Post (raw)\" if metric == metrics[0] else \"\"\n",
        "        )\n",
        "\n",
        "        # regression lines (forced through origin)\n",
        "        m_pre  = _fit_slope_through_origin(all_pre_days, all_pre_vals)\n",
        "        m_post = _fit_slope_through_origin(all_post_days, all_post_vals)\n",
        "\n",
        "        if np.isfinite(m_pre):\n",
        "            x_pre = np.linspace(all_pre_days.min(), 0, 100)\n",
        "            ax.plot(x_pre, m_pre * x_pre, color=\"#6A1B9A\", lw=2,\n",
        "                    label=\"Pre (fit)\" if metric == metrics[0] else \"\")\n",
        "        if np.isfinite(m_post):\n",
        "            x_post = np.linspace(0, all_post_days.max(), 100)\n",
        "            ax.plot(x_post, m_post * x_post, color=\"#FF00B3\", lw=2,\n",
        "                    label=\"Post (fit)\" if metric == metrics[0] else \"\")\n",
        "\n",
        "        # print slope values per week\n",
        "        print(f\"{metric}: pre slope = {m_pre*7:.4f} per week, post slope = {m_post*7:.4f} per week\")\n",
        "\n",
        "        ax.axvline(0, color=\"k\", lw=1)\n",
        "        ax.axhline(0, color=\"k\", lw=1)\n",
        "        ax.set_title(metric_display.get(metric, metric.replace('_', ' ')), fontsize=title_fontsize)\n",
        "        ax.grid(True, linestyle=\":\", alpha=0.6)\n",
        "\n",
        "        if metric == metrics[0]:\n",
        "            ax.set_ylabel(\"Normalized value\", fontsize=label_fontsize)\n",
        "        ax.set_xlabel(\"Days relative to flare\", fontsize=label_fontsize)\n",
        "\n",
        "    # Legend adapted to use font sizes\n",
        "    fig.legend(\n",
        "        loc=\"upper center\",\n",
        "        ncol=4,\n",
        "        frameon=False,\n",
        "        bbox_to_anchor=(0.5, 1.15),\n",
        "        fontsize=title_fontsize\n",
        "    )\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# Example call\n",
        "plot_overlay_all_metrics(summary_regular_flares,objective, metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"], min_days_threshold=10, method=\"AND\")"
      ],
      "metadata": {
        "id": "3JM3-odaBIAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_overlay_all_metrics(summary_symptom_flares, objective, metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"], min_days_threshold=10, method=\"AND\")"
      ],
      "metadata": {
        "id": "UXfBgm72x7kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Individual Slopes"
      ],
      "metadata": {
        "id": "p7nYSIBszQXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _span_correction(days_array, ref_span_days):\n",
        "\n",
        "    d = np.asarray(days_array, dtype=float)\n",
        "    if d.size == 0 or not np.isfinite(d).any():\n",
        "        return 1.0\n",
        "    span = np.nanmax(d) - np.nanmin(d)\n",
        "    if not np.isfinite(span) or span <= 0:\n",
        "        return 1.0\n",
        "    if not np.isfinite(ref_span_days) or ref_span_days <= 0:\n",
        "        return 1.0\n",
        "    return float(span) / float(ref_span_days)\n",
        "\n",
        "def plot_per_flare(\n",
        "    flare_df,\n",
        "    objective,\n",
        "    metrics,\n",
        "    pre_days=45,\n",
        "    post_days=45,\n",
        "    alpha=0.15,\n",
        "    point_size=10,\n",
        "    min_days_threshold=10,\n",
        "    method=\"OR\",\n",
        "    normalize_spans=True,\n",
        "):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # ---------- Display names + font sizes ----------\n",
        "    metric_display = {\n",
        "        \"REM_pct\": \"REM Sleep (%)\",\n",
        "        \"deep_pct\": \"Deep Sleep (%)\",\n",
        "        \"light_pct\": \"Light Sleep (%)\",\n",
        "        \"sleep_eff\": \"Sleep Efficiency (%)\",\n",
        "        \"dur_asleep\": \"Total Time Asleep (h)\",\n",
        "        \"sleep\": \"Subj. Sleep Score\"}\n",
        "    title_fontsize = 14\n",
        "    label_fontsize = 12\n",
        "    # ------------------------------------------------\n",
        "\n",
        "    # Prepare data\n",
        "    df = objective.copy()\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    fl = flare_df.copy()\n",
        "    fl[\"date_flare_onset\"] = pd.to_datetime(fl[\"date_flare_onset\"])\n",
        "    fl[\"date_flare_end\"]   = pd.to_datetime(fl[\"date_flare_end\"])\n",
        "\n",
        "    # Helper to check global threshold\n",
        "    def _threshold_ok(n_pre, n_post):\n",
        "        m = method.upper()\n",
        "        if m == \"AND\":\n",
        "            return (n_pre >= min_days_threshold) and (n_post >= min_days_threshold)\n",
        "        elif m == \"OR\":\n",
        "            return (n_pre >= min_days_threshold) or (n_post >= min_days_threshold)\n",
        "        else:\n",
        "            raise ValueError(\"method must be 'AND' or 'OR'\")\n",
        "\n",
        "    # First pass: decide which flares to include (rows)\n",
        "    rows = []  # each: dict with flare_id, uid, start, end, pre, post, flare\n",
        "    for flare_id, row in fl.reset_index(drop=True).iterrows():\n",
        "        uid   = row[\"user_id\"]\n",
        "        start = row[\"date_flare_onset\"]\n",
        "        end   = row[\"date_flare_end\"]\n",
        "\n",
        "        u = df[df[\"user_id\"] == uid].copy()\n",
        "        if u.empty:\n",
        "            continue\n",
        "\n",
        "        pre  = u[(u[\"date\"] >= start - pd.Timedelta(days=pre_days)) & (u[\"date\"] <  start)]\n",
        "        post = u[(u[\"date\"] >  end) & (u[\"date\"] <= end + pd.Timedelta(days=post_days))]\n",
        "        flare= u[(u[\"date\"] >= start) & (u[\"date\"] <= end)]\n",
        "\n",
        "        if flare.empty:\n",
        "            continue\n",
        "\n",
        "        n_pre, n_post = len(pre), len(post)\n",
        "        if not _threshold_ok(n_pre, n_post):\n",
        "            continue\n",
        "\n",
        "        # does ANY metric have usable finite pre or post values?\n",
        "        any_metric = False\n",
        "        for metric in metrics:\n",
        "            base = np.nanmean(flare[metric].values.astype(float))\n",
        "            if not np.isfinite(base):\n",
        "                continue\n",
        "            pre_vals  = pre[metric].values.astype(float)  if not pre.empty  else np.array([])\n",
        "            post_vals = post[metric].values.astype(float) if not post.empty else np.array([])\n",
        "            if (pre_vals.size and np.isfinite(pre_vals).any()) or (post_vals.size and np.isfinite(post_vals).any()):\n",
        "                any_metric = True\n",
        "                break\n",
        "\n",
        "        if any_metric:\n",
        "            rows.append(dict(\n",
        "                flare_id=flare_id,\n",
        "                uid=uid, start=start, end=end,\n",
        "                pre=pre, post=post, flare=flare\n",
        "            ))\n",
        "\n",
        "    n_rows = len(rows)\n",
        "    n_cols = len(metrics)\n",
        "\n",
        "    # If nothing qualifies, show one empty row with notes\n",
        "    if n_rows == 0:\n",
        "        fig, axes = plt.subplots(1, n_cols, figsize=(4*n_cols, 3), sharey=False)\n",
        "        if n_cols == 1:\n",
        "            axes = [axes]\n",
        "        for j, (ax, metric) in enumerate(zip(axes, metrics)):\n",
        "            ax.axvline(0, color=\"k\", lw=1)\n",
        "            ax.axhline(0, color=\"k\", lw=1)\n",
        "            ax.grid(True, linestyle=\":\", alpha=0.6)\n",
        "            ax.set_title(metric_display.get(metric, metric.replace('_', ' ')), fontsize=title_fontsize)\n",
        "            ax.set_xlabel(\"Days relative to flare\", fontsize=label_fontsize)\n",
        "            if j == 0:\n",
        "                ax.set_ylabel(\"Normalized value\", fontsize=label_fontsize)\n",
        "            ax.text(0.5, 0.5, \"No flares with usable data\", transform=ax.transAxes,\n",
        "                    ha=\"center\", va=\"center\", alpha=0.6)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "    # Create one big grid: rows=flares, cols=metrics\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3*n_rows), sharey=False)\n",
        "    # Normalize axes to 2D array\n",
        "    import numpy as _np  # alias to avoid shadowing above np, if any\n",
        "    if n_rows == 1 and n_cols == 1:\n",
        "        axes = _np.array([[axes]])\n",
        "    elif n_rows == 1:\n",
        "        axes = _np.array([axes])\n",
        "    elif n_cols == 1:\n",
        "        axes = _np.array([[ax] for ax in axes])\n",
        "\n",
        "    # Decorator for empty cells\n",
        "    def _decorate_empty(ax, metric, first_col, msg=\"No data in window\"):\n",
        "        ax.axvline(0, color=\"k\", lw=1)\n",
        "        ax.axhline(0, color=\"k\", lw=1)\n",
        "        ax.grid(True, linestyle=\":\", alpha=0.6)\n",
        "        ax.set_title(metric_display.get(metric, metric.replace('_', ' ')), fontsize=title_fontsize)\n",
        "        ax.set_xlabel(\"Days relative to flare\", fontsize=label_fontsize)\n",
        "        if first_col:\n",
        "            ax.set_ylabel(\"Normalized value\", fontsize=label_fontsize)\n",
        "        ax.text(0.5, 0.5, msg, transform=ax.transAxes, ha=\"center\", va=\"center\", alpha=0.6)\n",
        "\n",
        "    # --- Plot each row/flare ---\n",
        "    for i, entry in enumerate(rows):\n",
        "        uid   = entry[\"uid\"]\n",
        "        start = entry[\"start\"]\n",
        "        end   = entry[\"end\"]\n",
        "        pre   = entry[\"pre\"]\n",
        "        post  = entry[\"post\"]\n",
        "        flare = entry[\"flare\"]\n",
        "\n",
        "        print(f\"\\n=== Flare {entry['flare_id']}, user {uid} ===\")\n",
        "\n",
        "        for j, metric in enumerate(metrics):\n",
        "            ax = axes[i, j]\n",
        "            first_col = (j == 0)\n",
        "\n",
        "            base = np.nanmean(flare[metric].values.astype(float))\n",
        "            if not np.isfinite(base):\n",
        "                _decorate_empty(ax, metric, first_col, msg=\"No valid values for metric\")\n",
        "                continue\n",
        "\n",
        "            all_pre_days, all_pre_vals = [], []\n",
        "            all_post_days, all_post_vals = [], []\n",
        "\n",
        "            if not pre.empty:\n",
        "                d = (pre[\"date\"] - start).dt.days.values\n",
        "                y = pre[metric].values.astype(float) - base\n",
        "                mask = np.isfinite(y)\n",
        "                all_pre_days.extend(d[mask])\n",
        "                all_pre_vals.extend(y[mask])\n",
        "\n",
        "            if not post.empty:\n",
        "                d = (post[\"date\"] - end).dt.days.values\n",
        "                y = post[metric].values.astype(float) - base\n",
        "                mask = np.isfinite(y)\n",
        "                all_post_days.extend(d[mask])\n",
        "                all_post_vals.extend(y[mask])\n",
        "\n",
        "            all_pre_days, all_pre_vals   = np.array(all_pre_days),  np.array(all_pre_vals)\n",
        "            all_post_days, all_post_vals = np.array(all_post_days), np.array(all_post_vals)\n",
        "\n",
        "            # If this metric has zero usable points, render empty axis\n",
        "            if all_pre_days.size == 0 and all_post_days.size == 0:\n",
        "                _decorate_empty(ax, metric, first_col, msg=\"No finite pre/post values\")\n",
        "                continue\n",
        "\n",
        "            # scatter (raw)\n",
        "            if all_pre_days.size > 0:\n",
        "                ax.scatter(all_pre_days, all_pre_vals, color=\"#6A1B9A\", alpha=alpha, s=point_size, label=\"Pre (raw)\")\n",
        "            if all_post_days.size > 0:\n",
        "                ax.scatter(all_post_days, all_post_vals, color=\"#FF00B3\", alpha=alpha, s=point_size, label=\"Post (raw)\")\n",
        "\n",
        "            # slopes (through origin)\n",
        "            m_pre_raw  = _fit_slope_through_origin(all_pre_days,  all_pre_vals)  if all_pre_days.size  > 1 else np.nan\n",
        "            m_post_raw = _fit_slope_through_origin(all_post_days, all_post_vals) if all_post_days.size > 1 else np.nan\n",
        "\n",
        "            # normalize to fixed span\n",
        "            m_pre = m_pre_raw\n",
        "            m_post = m_post_raw\n",
        "            if normalize_spans and np.isfinite(m_pre_raw):\n",
        "                m_pre = m_pre_raw * _span_correction(all_pre_days, pre_days)\n",
        "            if normalize_spans and np.isfinite(m_post_raw):\n",
        "                m_post = m_post_raw * _span_correction(all_post_days, post_days)\n",
        "\n",
        "            # lines\n",
        "            if np.isfinite(m_pre) and all_pre_days.size > 0:\n",
        "                x_pre = np.linspace(all_pre_days.min(), 0, 100)\n",
        "                ax.plot(x_pre, m_pre * x_pre, color=\"#6A1B9A\", lw=2, label=\"Pre (fit)\")\n",
        "            if np.isfinite(m_post) and all_post_days.size > 0:\n",
        "                x_post = np.linspace(0, all_post_days.max(), 100)\n",
        "                ax.plot(x_post, m_post * x_post, color=\"#FF00B3\", lw=2, label=\"Post (fit)\")\n",
        "\n",
        "            # print slope values per week (normalized if enabled)\n",
        "            if np.isfinite(m_pre) or np.isfinite(m_post):\n",
        "                note = \" (normalized to ref span)\" if normalize_spans else \"\"\n",
        "                print(f\"{metric}: pre slope = {m_pre*7:.4f} per week, post slope = {m_post*7:.4f} per week{note}\")\n",
        "\n",
        "            # aesthetics + labels\n",
        "            ax.axvline(0, color=\"k\", lw=1)\n",
        "            ax.axhline(0, color=\"k\", lw=1)\n",
        "            ax.grid(True, linestyle=\":\", alpha=0.6)\n",
        "            ax.set_title(metric_display.get(metric, metric.replace('_', ' ')), fontsize=title_fontsize)\n",
        "            ax.set_xlabel(\"Days relative to flare\", fontsize=label_fontsize)\n",
        "            if first_col:\n",
        "                ax.set_ylabel(\"Normalized value\", fontsize=label_fontsize)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "A3WbvkSdHvIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_per_flare(\n",
        "    summary_regular_flares,\n",
        "    objective,\n",
        "    metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"],\n",
        "    min_days_threshold=10,\n",
        "    method=\"AND\",\n",
        "    pre_days=45,\n",
        "    post_days=45,\n",
        "    normalize_spans=True\n",
        ")"
      ],
      "metadata": {
        "id": "ZjXTqwVYxf8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_per_flare(\n",
        "    summary_symptom_flares,\n",
        "    objective,\n",
        "    metrics=[\"REM_pct\", \"deep_pct\", \"light_pct\", \"sleep_eff\", \"dur_asleep\"],\n",
        "    min_days_threshold=10,\n",
        "    method=\"AND\",\n",
        "    pre_days=45,\n",
        "    post_days=45,\n",
        "    normalize_spans=True\n",
        ")"
      ],
      "metadata": {
        "id": "uPFEaZJYxZ_L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}